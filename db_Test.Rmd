---
title: "Untitled"
author: "Ana Macanovic"
date: "2024-01-15"
output: html_document
---

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```

Load the packages:
```{r message=  F, warning = F}
library(groundhog)
packages_to_load <- c("readr", "dplyr", "dbplyr",
                      "stringr", "lubridate",
                      "tidyr", "tidyverse",
                      "RPostgres",
                      "DBI", "RODBC", "odbc")
groundhog.library(packages_to_load, date = "2023-12-01")

```

# Load helper data

Load the professor profiles:
```{r message = F, warning = F}
load("raw_data/media_profs_profiles.rda")
profs <- read_csv("raw_data/dutch_profs_urls.csv")

# merge the profs with their ORCIDs
colnames(profs)[c(1,7)] <- c("id", "profile_id")

profs_full <- merge(profs,
                    metadf[, c(1:4, 361)],
                    by = "profile_id")
```

Connect to the postgres database:
```{r}
dsn_database <- "DutchMediaProfs"
dsn_hostname <- "localhost"
dsn_port <- 5432
dsn_uid <- "postgres"
dsn_pwd <- "dutchmediaprofssql"

con <- RPostgres::dbConnect(RPostgres::Postgres(),
                 dbname= dsn_uid,
                 port = dsn_port,
                 user = dsn_uid, 
                 password = dsn_pwd)


con # Checks connection is working
```
# Populate the database

## Identifier list

Write out the identifier list to a table in the SQL database:
```{r}
prof_identifier_list <- readRDS("~/Postdoc/Projects/dutch_media_profs_r/processed_data/prof_oa_identifier_list.RDS")

prof_oa_mapping <- data.frame(matrix(NA, nrow = 0, ncol = 3))

for (i in 1:length(prof_identifier_list)){
  # initiate a dataframe to store this professor's data
  prof_oa_ids <- data.frame(matrix(NA, nrow = 0, ncol = 3))
  # retrieve this professor's list of identifiers
  prof_identifiers <- prof_identifier_list[[i]]
  # get their Narcis ID and all the retrieved OA IDs
  narcis_id <- prof_identifier_list[[i]][["narcis_id"]]
  
  pub_ids <- prof_identifier_list[[i]][["oa_ids_pubs"]]
  
  orcid_ids <- prof_identifier_list[[i]][["oa_ids_orcid"]]
  
  name_ids <- prof_identifier_list[[i]][["oa_ids_names"]]
  
  # add any IDs retrieved from the publication list
  if (!all(is.na(pub_ids))){
  
  pub_ids <- cbind.data.frame("profile_id" = narcis_id,
                              "oa_id" = pub_ids,
                              "source" = "publications")
  
  prof_oa_ids <- rbind(prof_oa_ids,
                       pub_ids)
  }
  # add any IDs associated with prof's ORCID
  if (!all(is.na(orcid_ids))){
  orcid_ids <- cbind.data.frame("profile_id" = narcis_id,
                              "oa_id" = orcid_ids,
                              "source" = "orcid")
  
  prof_oa_ids <- rbind(prof_oa_ids,
                       orcid_ids)
  }
  # add any IDs from name search + NL country
  if (!all(is.na(name_ids))){
  name_ids <- cbind.data.frame("profile_id" = narcis_id,
                              "oa_id" = name_ids,
                              "source" = "name")
  
  prof_oa_ids <- rbind(prof_oa_ids,
                       name_ids)
  }
  
  # if any rows
  if (nrow(prof_oa_ids) > 0){
    
    # deduplicate
    prof_oa_ids$duplicate <- duplicated(prof_oa_ids[c("profile_id", "oa_id")])
    prof_oa_ids <- filter(prof_oa_ids,
                          duplicate == FALSE)
    prof_oa_ids <- prof_oa_ids[, -4]
    
    prof_oa_mapping <- rbind(prof_oa_mapping,
                             prof_oa_ids)
  } else{
    prof_oa_ids <- cbind.data.frame("profile_id" = narcis_id,
                                    "oa_id" = NA,
                                    "source" = NA)
    prof_oa_mapping <- rbind(prof_oa_mapping,
                             prof_oa_ids)
  }
  #print(paste("done with", i, "out of", length(narcis_ids)))
}


dbWriteTable(con, "oa_identifier_table", prof_oa_mapping, row.names=FALSE, append=TRUE)
```

## Gender data
```{r}
profs_full_gender <- readRDS("~/Postdoc/Projects/dutch_media_profs_r/processed_data/profs_full_gender.RDS")
dbWriteTable(con, "gender_table", profs_full_gender, row.names=FALSE, append=TRUE)
```

## ORCIDs

```{r}
prof_orcid_mapping <- data.frame(matrix(NA, nrow = 0, ncol = 1))

for (i in 1:length(prof_identifier_list)){
  # retrieve this professor's list of identifiers
  prof_identifiers <- prof_identifier_list[[i]]
  # get their Narcis ID and all the retrieved OA IDs
  narcis_id <- prof_identifier_list[[i]][["narcis_id"]]
  
  orcid_ids <- prof_identifier_list[[i]][["oa_ids_orcid"]]

  
  ids <- cbind.data.frame("profile_id" = narcis_id,
                              "orcid" = orcid_ids)
  
  prof_orcid_mapping <- rbind(prof_orcid_mapping,
                          ids)
  #print(paste("done with", i, "out of", length(narcis_ids)))
}

dbWriteTable(con, "orcid_table", prof_orcid_mapping, row.names=FALSE, append=TRUE)
```

## Create tables for info in professor lists
```{r}
dbRemoveTable(con, "prof_info")
dbRemoveTable(con, "affiliation_info")
dbRemoveTable(con, "grant_info")
dbRemoveTable(con, "coauthor_info")
dbRemoveTable(con, "news_mentions")
dbRemoveTable(con, "wiki_mentions")
dbRemoveTable(con, "reddit_mentions")
dbRemoveTable(con, "narcis_pubs")
dbRemoveTable(con, "oa_pubs")
dbRemoveTable(con, "oa_concepts")
```


## Extract info from professor lists
```{r}
# helper elements for mention padding
# mention_cols <- c("wikipedia", "news", "patent", "blogs", "googleplus", 
#                   "facebook", "reddit", "f1000", "policy", "peer_reviews",
#                   "video", "q&a", "misc", "weibo", "pinterest", "syllabi",
#                   "linkedin", "book_reviews")

# get the list of IDs
narcis_ids <- profs_full$profile_id
# query in batches
# batch size
prof_batch_size <- 500
# vector of indices to loop through
batches <- seq(from=1, to=length(narcis_ids), by=prof_batch_size)
# to be able to subset, also add the final index+1
batches <- c(batches, length(narcis_ids)+1)

# loop through the batches
for(i in 1:(length(batches)-1)){
 # load the batch
  read_string <- paste0("processed_data/open_alex_prof_data/", paste("prof_data_batch", i, sep = "_"), ".RDS")
  batch_prof_outcomes <- readRDS(read_string)
  
  # get the narcis ids from the batch
  prof_batch <- narcis_ids[batches[i]:(batches[i+1]-1)]


  for (j in 1:length(prof_batch)){
    prof <- batch_prof_outcomes[[j]]
    prof_id <- names(batch_prof_outcomes[j])
    # if some data in the prof list
    if (length(prof)>1){
      ## get the professor info
      prof_info <- prof[["prof_info"]]
      # if not empty
      if (!all(is.na(prof_info))){
        # remove columns we do not need
        if(any(c("x_concepts","display_name_alternatives", "ids", "affiliation_lineage") %in% colnames(prof_info))){
          prof_info <- prof_info %>%
            select(!any_of(c("x_concepts", "display_name_alternatives", "ids", "affiliation_lineage")))
        }
        # now unnest the data
        prof_info_unnest <- unnest(prof_info, cols = c(counts_by_year), names_sep = "_year_")
        # append the prof id
        prof_info_unnest <- bind_cols("profile_id" = prof_id,
                                      prof_info_unnest)
        if ((i == 1) & (j == 1)){
        # and write to the database
        dbWriteTable(con, "prof_info", prof_info_unnest, row.names=FALSE, append=TRUE)
        }else{
          # check fields in the existing table
          fields <- dbListFields(con, "prof_info")
          # if not all fields there
          if(!all(fields %in% colnames(prof_info_unnest))){
            n_missing <- which(!fields %in% colnames(prof_info_unnest))
            padding <- data.frame(matrix(NA, ncol = length(n_missing), nrow=1))
            colnames(padding) <- fields[which(!fields %in% colnames(prof_info_unnest))]
            prof_info_unnest <- bind_cols(prof_info_unnest,
                                          padding)
            prof_info_unnest <- prof_info_unnest[fields]
          }
          # only leave these fields in
          prof_info_unnest <-  prof_info_unnest %>%
            select(all_of(fields))
          
          dbAppendTable(con, "prof_info", prof_info_unnest, row.names=NULL, append=TRUE)
        }
      }
      
      ## get the NARCIS publications
      narcis_pubs <- prof[["narcis_pubs"]]
      # if not empty
      if (!all(is.na(narcis_pubs)) & class(narcis_pubs) != "character"){
        # if first round, create a table
        if ((i == 1) & (j == 1)){
          # write to the database
          dbWriteTable(con, "narcis_pubs", narcis_pubs, row.names=FALSE, append=TRUE)
          # otherwise, append
        }else{
          # check fields in the existing table
          fields <- dbListFields(con, "narcis_pubs")
          # only leave these fields in
          narcis_pubs <-  narcis_pubs %>%
            select(all_of(fields))
          dbAppendTable(con, "narcis_pubs", narcis_pubs, row.names=NULL, append=TRUE)
        }
      }
      
      ## get the OA publications
      oa_pubs <- prof[["oa_pubs"]]
      
      # if not empty
      if (!all(is.na(oa_pubs))){
        # first, get the mention data
        mention_data <- oa_pubs %>%
          select(id, profile_id, author_position:last_col(), -author_position)
        
        # if not empty
        if (!all(is.na(mention_data))){
          
          # if there's wiki data
          if ('wikipedia' %in% colnames(mention_data)){
            wiki_mention_data_unnest <- mention_data%>%
              select(id, profile_id, wikipedia) %>%
              unnest(., cols = 'wikipedia')%>%
              select(!citation_ids)%>%
              unnest(., cols = author, names_sep = "_au_")
            
            # if first round, create a table
            if ((i == 1) & (j == 1)){
              # write to the database
              dbWriteTable(con, "wiki_mentions", wiki_mention_data_unnest, row.names=FALSE, append=TRUE)
              # otherwise, append
            }else{
              # check fields in the existing table
              fields <- dbListFields(con, "wiki_mentions")
              # if not all fields there
              if(!all(fields %in% colnames(wiki_mention_data_unnest))){
                n_missing <- which(!fields %in% colnames(wiki_mention_data_unnest))
                padding <- data.frame(matrix(NA, ncol = length(n_missing), nrow=1))
                colnames(padding) <- fields[which(!fields %in% colnames(wiki_mention_data_unnest))]
                wiki_mention_data_unnest <- bind_cols(wiki_mention_data_unnest,
                                              padding)
                wiki_mention_data_unnest <- wiki_mention_data_unnest[fields]
              }
              # only leave these fields in
              wiki_mention_data_unnest <-  wiki_mention_data_unnest %>%
                select(all_of(fields))
              dbAppendTable(con, "wiki_mentions", wiki_mention_data_unnest, row.names=NULL, append=TRUE)
            }
          }
          # if there's news data
          if ('news' %in% colnames(mention_data)){
            news_mention_data_unnest <- mention_data%>%
              select(id, profile_id, news) %>%
              unnest(., cols = 'news')%>%
              select(!citation_ids)%>%
              unnest(., cols = author, names_sep = "_au_")
            
            # if first round, create a table
            if ((i == 1) & (j == 1)){
              # write to the database
              dbWriteTable(con, "news_mentions", news_mention_data_unnest, row.names=FALSE, append=TRUE) 
              # otherwise, append
            }else{
              # check fields in the existing table
              fields <- dbListFields(con, "news_mentions")
              # if not all fields there
              if(!all(fields %in% colnames(news_mention_data_unnest))){
                n_missing <- which(!fields %in% colnames(news_mention_data_unnest))
                padding <- data.frame(matrix(NA, ncol = length(n_missing), nrow=1))
                colnames(padding) <- fields[which(!fields %in% colnames(news_mention_data_unnest))]
                news_mention_data_unnest <- bind_cols(news_mention_data_unnest,
                                                      padding)
                news_mention_data_unnest <- news_mention_data_unnest[fields]
              }
              
              # only leave these fields in
              news_mention_data_unnest <-  news_mention_data_unnest %>%
                select(all_of(fields))
              dbAppendTable(con, "news_mentions", news_mention_data_unnest, row.names=NULL, append=TRUE) 
            }
          }
          
          # # if there's FB data, but this doesn't work 
          # if ('facebook' %in% colnames(mention_data)){
          #   fb_mention_data_unnest <- mention_data%>%
          #     select(id, profile_id, facebook) %>%
          #     unnest(., cols = 'facebook')%>%
          #     select(!citation_ids)
          # 
          # }
          
          # if there's reddit data
          if ('reddit' %in% colnames(mention_data)){
            reddit_mention_data_unnest <- mention_data%>%
              select(id, profile_id, reddit) %>%
              unnest(., cols = 'reddit')%>%
              select(!citation_ids)%>%
              unnest(., cols = author, names_sep = "_au_")
            
            if ((i == 1) & (j == 1)){
              # write to the database
              dbWriteTable(con, "reddit_mentions", reddit_mention_data_unnest, row.names=FALSE, append=TRUE) 
              # otherwise, append
            }else{
              # check fields in the existing table
              fields <- dbListFields(con, "reddit_mentions")
              if(!all(fields %in% colnames(reddit_mention_data_unnest))){
                n_missing <- which(!fields %in% colnames(reddit_mention_data_unnest))
                padding <- data.frame(matrix(NA, ncol = length(n_missing), nrow=1))
                colnames(padding) <- fields[which(!fields %in% colnames(reddit_mention_data_unnest))]
                reddit_mention_data_unnest <- bind_cols(reddit_mention_data_unnest,
                                                      padding)
                reddit_mention_data_unnest <- reddit_mention_data_unnest[fields]
              }
              # only leave these fields in
              reddit_mention_data_unnest <-  reddit_mention_data_unnest %>%
                select(all_of(fields))
              dbAppendTable(con, "reddit_mentions", reddit_mention_data_unnest, row.names=NULL, append=TRUE) 
            }
          }
        }
        
        # now, get the publication data
        # select relevant columns
        select_cols <- c("id", "profile_id", "display_name", "ab", "publication_year",
                         "so", "so_id", "host_organization", "issn_l", 
                         "url", "pdf_url", "volume", "issue", "first_page", 
                         "last_page", " is_ia", "language",
                         "cited_by_count", "counts_by_year", "cited_by_api_url",
                         "doi", "type", 
                         "is_retracted", "ia_id", 
                         "author_position")
        pub_data <- oa_pubs %>%
          select(any_of(select_cols))
        
        # get the referenced works
        referenced_works <- oa_pubs %>%
          select(id, profile_id, referenced_works)%>%
          unnest(., cols = "referenced_works")
        
        # get the counts by year
        pub_by_year <- pub_data %>%
          unnest(., cols = "counts_by_year", names_sep = "_year_")
        
        # write this out
        # if not empty
        if (!all(is.na(oa_pubs))){
          if ((i == 1) & (j == 1)){
            # write to the database
            dbWriteTable(con, "oa_pubs", pub_by_year, row.names=FALSE, append=TRUE)
            # otherwise, append
          }else{
            # check fields in the existing table
            fields <- dbListFields(con, "oa_pubs")
            # if some missing, pad the dataset
            if(!all(fields %in% colnames(pub_by_year))){
              n_missing <- which(!fields %in% colnames(pub_by_year))
              padding <- data.frame(matrix(NA, ncol = length(n_missing), nrow=1))
              colnames(padding) <- fields[which(!fields %in% colnames(pub_by_year))]
              pub_by_year <- bind_cols(pub_by_year,
                                                      padding)
              pub_by_year <- pub_by_year[fields]
            }
            # only leave these fields in
            pub_by_year <-  pub_by_year %>%
              select(all_of(fields))
            dbAppendTable(con, "oa_pubs", pub_by_year, row.names=NULL, append=TRUE)
          }
        }
        
        # unnest the concepts, but also leave only those on levels 0 and 1 and with prob
        # above 0.5
        oa_concepts <- oa_pubs %>%
          select(id, profile_id, concepts)%>%
          unnest(., cols = "concepts", names_sep = "_conc_")%>%
          filter(concepts_conc_level %in% c(0,1) & concepts_conc_score >= 0.5)
        
        # write this out
        # if not empty
        if (!all(is.na(oa_concepts))){
          if ((i == 1) & (j == 1)){
            # write to the database
            dbWriteTable(con, "oa_concepts", oa_concepts, row.names=FALSE, append=TRUE) 
            # otherwise, append
          }else{
            # check fields in the existing table
            fields <- dbListFields(con, "oa_concepts")
            # if some fields missing, pad the dataset
            if(!all(fields %in% colnames(oa_concepts))){
              n_missing <- which(!fields %in% colnames(oa_concepts))
              padding <- data.frame(matrix(NA, ncol = length(n_missing), nrow=1))
              colnames(padding) <- fields[which(!fields %in% colnames(oa_concepts))]
              oa_concepts <- bind_cols(oa_concepts,
                                       padding)
              oa_concepts <- oa_concepts[fields]
            }
            # only leave these fields in
            oa_concepts <-  oa_concepts %>%
              select(all_of(fields))
            dbAppendTable(con, "oa_concepts", oa_concepts, row.names=NULL, append=TRUE)
          }
        }
      }
      
      ## get the grant info
      grant_info <- prof[["grant_info"]]
      # and write to the database
      # if not empty
      if (!all(is.na(grant_info))){
        if ((i == 1) & (j == 1)){
          # write to the database
          dbWriteTable(con, "grant_info", grant_info, row.names=FALSE, append=TRUE)
          # otherwise, append
        }else{
          # check fields in the existing table
          fields <- dbListFields(con, "grant_info")
          if(!all(fields %in% colnames(grant_info))){
            n_missing <- which(!fields %in% colnames(grant_info))
            padding <- data.frame(matrix(NA, ncol = length(n_missing), nrow=1))
            colnames(padding) <- fields[which(!fields %in% colnames(grant_info))]
            grant_info <- bind_cols(grant_info,
                                     padding)
            grant_info <- grant_info[fields]
          }
          # only leave these fields in
          grant_info <-  grant_info %>%
            select(all_of(fields))
          dbAppendTable(con, "grant_info", grant_info, row.names=NULL, append=TRUE)
        }
      
      }
      
      ## get the coauthor info
      coauthor_info <- prof[["coauthor_info"]]
      # and write to the database
      # if not empty
      if (!all(is.na(coauthor_info))){
        if ((i == 1) & (j == 1)){
          # write to the database
          dbWriteTable(con, "coauthor_info", coauthor_info, row.names=FALSE, append=TRUE) 
          # otherwise, append
        }else{
          # check fields in the existing table
          fields <- dbListFields(con, "coauthor_info")
          # if needed, pad the dataset
          if(!all(fields %in% colnames(coauthor_info))){
            n_missing <- which(!fields %in% colnames(coauthor_info))
            padding <- data.frame(matrix(NA, ncol = length(n_missing), nrow=1))
            colnames(padding) <- fields[which(!fields %in% colnames(coauthor_info))]
            coauthor_info <- bind_cols(coauthor_info,
                                    padding)
            coauthor_info <- coauthor_info[fields]
          }
          # only leave these fields in
          coauthor_info <-  coauthor_info %>%
            select(all_of(fields))
          dbAppendTable(con, "coauthor_info", coauthor_info, row.names=NULL, append=TRUE) 
        }
      }
      
      ## get the affiliation info
      affiliation_info <- prof[["affiliation_info"]]
      # if not empty
      if (!all(is.na(affiliation_info))){
        # and write to the database
        if ((i == 1) & (j == 1)){
          # write to the database
          dbWriteTable(con, "affiliation_info", affiliation_info, row.names=FALSE, append=TRUE) 
          # otherwise, append
        }else{
          # check fields in the existing table
          fields <- dbListFields(con, "affiliation_info")
          # if needed, pad the dataset
          if(!all(fields %in% colnames(affiliation_info))){
            n_missing <- which(!fields %in% colnames(affiliation_info))
            padding <- data.frame(matrix(NA, ncol = length(n_missing), nrow=1))
            colnames(padding) <- fields[which(!fields %in% colnames(affiliation_info))]
            affiliation_info <- bind_cols(affiliation_info,
                                       padding)
            affiliation_info <- affiliation_info[fields]
          }
          
          # only leave these fields in
          affiliation_info <-  affiliation_info %>%
            select(all_of(fields))
          dbAppendTable(con, "affiliation_info", affiliation_info, row.names=NULL, append=TRUE)  
        }
      }
    }
    
    print(paste("done with", j, "out of", length(prof_batch)))
    
  }
}
```




```{r}
oa_colnames_all <- c()
for (j in 1:length(prof_batch)){
  prof <- prof_batch[[j]]
  prof_id <- names(prof_batch[j])
  # if some data in the prof list
  if (length(prof)>1){
    # get the OA publications
    oa_pubs <- prof[["oa_pubs"]]
    if (!all(is.na(oa_pubs))){
      oa_colnames <- colnames(oa_pubs)
      
      oa_colnames_all <- c(oa_colnames_all,
                           oa_colnames[which(!oa_colnames %in% oa_colnames_all)])
    }
  }
}
    
    # select relevant columns
    cols <- c("id", "display_name", "ab", "publication_year",
               "so", "so_id", "host_organization", "issn_l", 
              "url", "pdf_url", "volume", "issue", "first_page", 
               "last_page", " is_ia", " language",
               "cited_by_count", " counts_by_year", " cited_by_api_url",
               "ids", " doi", " type", " referenced_works", " related_works",
               "is_retracted", " concepts", " ia_id", " profile_id", 
               "author_position")
    # and whatever is 
    
    oa_pubs_2 <- oa_pubs %>%
        select(id, display_name, ab, publication_year,
               so, so_id, host_organization, issn_l,
               url, pdf_url, volume, issue, first_page,
               last_page, is_ia, language,
               cited_by_count, counts_by_year, cited_by_api_url, 
               ids, doi, type, referenced_works, related_works,
               is_retracted, concepts, ia_id, profile_id,
               author_position)
    
    
    # unnest the concepts, but also leave only those on levels 0 and 1 and with prob
    # above 0.5
    oa_pubs_unnested <- unnest(oa_pubs, cols = "concepts", names_sep = "_conc_")%>%
      filter(concepts_conc_level %in% c(0,1) & concepts_conc_score >= 0.5)
    
    # append the prof ID
    oa_pubs <- bind_cols("profile_id" = prof_id,
                         oa_pubs)
    
    
    
    # and write to the database
    dbWriteTable(con, "oa_pubs", oa_pubs, row.names=FALSE, append=TRUE)
    
    
    
      }

      
  
}
```



