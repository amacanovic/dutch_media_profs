---
title: "Twitter_handle_extraction"
author: "Ana Macanovic"
date: "2023-12-06"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(eval = FALSE)
```

This script processes the output of our python scrip that pings Google Search API
and outputs the first result.

```{r warning = F, message = F}
library(groundhog)
packages_to_load <- c("readr", "dplyr", "stringr", "strex",
                      "stringdist", "RPostgres",
                      "DBI", "RODBC", "odbc")
groundhog.library(packages_to_load, date = "2023-12-01")
```

# Tidying up the names

Loading the output of the python script from our results folder:
```{r warning = F, message = F}
# getting all the csv files that were processed in batches
csv_names <- list.files(path = "~/Postdoc/Projects/dutch_media_profs_python/output-data/twitter",
                        pattern = "*.csv",
                        full.names = TRUE)

results_prof_google_search <- lapply(csv_names, read_csv) %>% 
  bind_rows() %>%
  arrange(`...1`)
```

It seems that the ```htmltitle``` field includes good hints as to whether
we found a handle of the person in question. Let us exploit that, searching for 
```<b>`` in that field, an @, and a "/X":
```{r}
# define the strings we want
search_values <- c("<b>", "</b>", "@", "\\) \\/ X")
# check if all of them there, if so, paste the title, if not, set to NA
results_prof_google_search$handle_text <- ifelse(str_detect_all(results_prof_google_search$htmlTitle, search_values) == TRUE,
                                                 results_prof_google_search$htmlTitle,
                                                 NA)
```

Preview this:
```{r}
knitr::kable(results_prof_google_search[1:10,c(4, 13, 16)], "html")
```


<br> 
Now, we should somehow:
1. Get the handle
2. Check the handle against the person's actual name

Let's split the strings at (@)
```{r}
# get the queries (some were dropped if no results found by google)
names <- results_prof_google_search$elem
# get the cleaned up title texts
handles <- results_prof_google_search$handle_text
# initialize a vector for storage
handle_list <- c()
alt_handle_list <- c()
name_check_list <- c()

for (i in 1:length(handles)){
  potential_handle <- handles[i]
  # first, spit the text
  split_handle_text <-  unlist(str_split(potential_handle, "\\(@"))
  
  # by default, assume no alternative handles (see below)
  alt_handle <- NA
  
  # if not empty
  if (!any(is.na(split_handle_text))){
    # get the name related to the handle for checking
    name_check <- unlist(split_handle_text)[1]
    # clean from <b>/ </b> if there
    name_check <- str_remove(name_check, "<b>")
    name_check <- str_remove(name_check, "</b>")
    # trim white spaces
    name_check <- trimws(name_check)
    
    # get the handle, cleaning from the closing bracket
    
    # but some people might list handles to other social media on their profiles
    # so, we want the last handle
    
    # let's get the alternative handles, if present
    if (length(split_handle_text) > 2){
      alt_handle <- unlist(str_remove(unlist(split_handle_text)[2], "\\) / X"))[1]
      # clean any additional <b>s
      alt_handle <- str_remove(alt_handle, "<b>")
      alt_handle <- str_remove(alt_handle, "</b>")
      alt_handle <- str_remove(alt_handle, "\\)")
      # add the @
      alt_handle <- paste0("@", alt_handle)
    }
    # but, if there are some others, let us fetch that as well...
    handle <- unlist(str_remove(unlist(split_handle_text)[length(split_handle_text)], "\\) / X"))[1]
    # clean any additional <b>s
    handle <- str_remove(handle, "<b>")
    handle <- str_remove(handle, "</b>")
    # add the @
    handle <- paste0("@", handle)
  } else{
    # if no handle in the result, set to NA
    handle <- NA
    name_check <- NA
  }
  
  # append whatever the handle is
  handle_list[i] <- handle
  alt_handle_list[i] <- alt_handle
  name_check_list[i] <- name_check

}

handle_dataframe <- cbind.data.frame(name = names,
                                     twitter_handle = handle_list,
                                     alt_handle = alt_handle_list,
                                     name_extracted = name_check_list,
                                     link = results_prof_google_search$link)

```

Get the string similarity between the Twitter name and the professor name:
```{r}
# tidy up the extracted names
handle_dataframe$name_extracted <- tolower(handle_dataframe$name_extracted)
handle_dataframe$name_extracted <- gsub("[^[:alnum:] ]", "", handle_dataframe$name_extracted)

# get string similarity
handle_dataframe$string_sim <- stringsim(handle_dataframe$name_extracted, handle_dataframe$name)
```

Write the results out for manual checking:
```{r}
write_csv(handle_dataframe, "twitter_handles/handle_extraction_raw.csv")
```

# Matching professors and names

We have manually checked the handles and noted the ones that match professors
in our dataset.

Load this manually evaluated table and only leve in the handles matching our
professors:
```{r warning = F, message=F}
checked_handles <- read_csv("twitter_handles/handle_extraction_checked.csv")

# filter by "correct" field (actual matches are denoted as "Y") and
# select relevant columns only
checked_handles <- checked_handles %>%
  filter(., correct == "Y")%>%
  select(name, twitter_handle, link)

# dedupe
checked_handles$dupl <- duplicated(checked_handles)

checked_handles <- checked_handles %>%
  filter(., dupl == FALSE)%>%
  select(-dupl)

# replace bad encodings
checked_handles$first_last <- str_replace_all(checked_handles$name, "\\Ã©", "é")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "\\Ã¨", "è")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "\\Ã«", "ë")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "Ã¶¨", "ö")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "Ã¶", "ö")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "\\Ã¼", "ü")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "\\Ã¡", "á")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "\\Ã³", "ó")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "\\Ã£", "ã")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "\\Ã¤", "ä")
checked_handles$first_last <- str_replace_all(checked_handles$first_last, "\\Ã¸l", "ø")
```

In total, we find handles for accounts of 1361 professors in our dataset
(almost 20% of all professors in out dataset):
```{r}
nrow(checked_handles)

round(nrow(checked_handles)/6830, 3)*100
```
Load professors' information and match it with their handles.

First, connect to our database:
```{r}
# default port here, change if needed
port <- 5432
# username
user <- ""
# password
password <- ""
# database name
database_name <- ""

con <- RPostgres::dbConnect(RPostgres::Postgres(),
                 dbname= database_name,
                 port = port,
                 user = user, 
                 password = password)

```

Load the professor profiles:
```{r message = F, warning = F}
profs_full <- dbReadTable(con, "narcis_prof_info")
```

And now match with handles by first+last name:
```{r}
profs_full$first_last <- tolower(paste(profs_full$first, profs_full$last))


prof_twitter_handles <- merge(profs_full[c("profile_id", "first_last")],
                              checked_handles[c("twitter_handle", "link", "first_last")],
                              by = "first_last",
                              all.y = TRUE)

# one is still not being recognize, so manually replace
prof_twitter_handles$profile_id[which(is.na(prof_twitter_handles$profile_id))] <- "https://www.narcis.nl/person/RecordID/PRS1337845"

# and it appears there are some duplicates?
check_dupl <- prof_twitter_handles %>%
  group_by(twitter_handle)%>%
  summarise(n = n())%>%
  arrange(-n)

# drop the ones that are linked wrong after checking manually:
drop <- c("https://www.narcis.nl/person/RecordID/PRS1242401",
          "https://www.narcis.nl/person/RecordID/PRS1305610",
          "https://www.narcis.nl/person/RecordID/PRS1270096",
          "https://www.narcis.nl/person/RecordID/PRS1290119")


prof_twitter_handles <- filter(prof_twitter_handles,
                               ! profile_id %in% drop)          
```

Write these out to the database:
```{r}
dbWriteTable(con, "twitter_handle_table", prof_twitter_handles)
```

