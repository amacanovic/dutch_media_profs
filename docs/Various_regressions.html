<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Ana Macanovic" />

<meta name="date" content="2024-02-29" />

<title>Untitled</title>

<script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/all.min.css" rel="stylesheet" />
<link href="site_libs/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
#rmd-source-code {
  display: none;
}
</style>


<link rel="stylesheet" href="tweaks.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a>
    <span class="fa fa-home"></span>
     
  </a>
</li>
<li>
  <a href="index.html">Code homepage</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    <span class="glyphicon glyphicon glyphicon glyphicon-list"></span>
     
    Scripts
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="SQL_tutorial.html">Intro: SQL tutorial</a>
    </li>
    <li>
      <a href="OpenAlex_Altmetric_data_download.html">1. Open Alex and Altmetric data download</a>
    </li>
    <li>
      <a href="Gender_inference.html">2. Gender inference</a>
    </li>
    <li>
      <a href="Grant_parsing.html">3. Grant parsing</a>
    </li>
    <li>
      <a href="Lexis_nexis_parser.html">4. Lexis data parser</a>
    </li>
    <li>
      <a href="Mention_url_extraction.html">5. Mention URL extraction</a>
    </li>
    <li>
      <a href="Data_descriptives.html">5. Database description and coverage</a>
    </li>
    <li>
      <a href="Panel_data_compilation.html">6. Panel data compilation</a>
    </li>
    <li>
      <a href="exploring_fame.html">7. Share of women in fame plots</a>
    </li>
    <li>
      <a href="Various_plots.html">8. Data plots</a>
    </li>
    <li>
      <a href="Various_regressions.html">9. Regression models</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/amacanovic/dutch_media_profs">
    <span class="fab fa-github"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Untitled</h1>
<h4 class="author">Ana Macanovic</h4>
<h4 class="date">2024-02-29</h4>

</div>


<pre class="r"><code>options(width = 120)
knitr::opts_chunk$set(cache = FALSE, cache.lazy = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)</code></pre>
<p>Load the packages:</p>
<pre class="r"><code>library(groundhog)
packages_to_load &lt;- c(&quot;readr&quot;, &quot;dplyr&quot;, &quot;tidyr&quot;, 
                      &quot;tidyverse&quot;, &quot;RPostgres&quot;, &quot;lubridate&quot;, &quot;psych&quot;,
                      &quot;gridExtra&quot;, &quot;DescTools&quot;,
                      &quot;panelr&quot;, &quot;skimr&quot;, &quot;car&quot;,&quot;ggeffects&quot;,
                      &quot;lmtest&quot;, &quot;sandwich&quot;,
                      &quot;stargazer&quot;,&quot;plm&quot;)
groundhog.library(packages_to_load, date = &quot;2023-12-01&quot;)</code></pre>
<div id="data-preparation" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Data preparation</h1>
<p>Load the panel:</p>
<pre class="r"><code>prof_panel &lt;- read_csv(&quot;panel_datasets/prof_year_p_c_g_a_t_l_l_18_3.csv&quot;)
prof_panel_coa &lt;- read_csv(&quot;panel_datasets/prof_panel_combined_no_lexis_19_3.csv&quot;)

# combine the two, since the latter mixes nexis data
lexis_data &lt;- prof_panel %&gt;%
  select(profile_id, year, contains(&quot;lexis&quot;))

prof_panel_coa &lt;- merge(prof_panel_coa,
                        lexis_data,
                        by= c(&quot;profile_id&quot;, &quot;year&quot;))

# recode the fields
prof_panel_coa &lt;- prof_panel_coa %&gt;% 
  mutate(general_field = case_match(
    overall_field,
    &quot;Arts and Humanities&quot;  ~ &quot;Arts &amp; Humanities&quot;,
    c(&quot;Biochemistry, Genetics and Molecular Biology&quot;,&quot;Agricultural and Biological Sciences&quot;,
      &quot;Chemical Engineering&quot;, &quot;Chemistry&quot;,  &quot;Computer Science&quot;, &quot;Decision Sciences&quot;,
      &quot;Earth and Planetary Sciences&quot;, &quot;Energy&quot;, &quot;Engineering&quot;, &quot;Environmental Science&quot;,
      &quot;Immunology and Microbiology&quot;, &quot;Materials Science&quot;, &quot;Mathematics&quot;, &quot;Neuroscience&quot;, 
      &quot;Physics and Astronomy&quot; ) ~ &quot;STEM&quot;,
    c(&quot;Dentistry&quot;, &quot;Health Professions&quot;, &quot;Medicine&quot;) ~ &quot;Medicine&quot;,
    c(&quot;Business, Management and Accounting&quot;, &quot;Economics, Econometrics and Finance&quot;,
      &quot;Psychology&quot;, &quot;Social Sciences&quot;) ~ &quot;Social sciences&quot;))

prof_panel_coa &lt;- prof_panel_coa %&gt;% 
  mutate(general_field_yearly = case_match(
    yearly_field,
    &quot;Arts and Humanities&quot;  ~ &quot;Arts &amp; Humanities&quot;,
    c(&quot;Biochemistry, Genetics and Molecular Biology&quot;,&quot;Agricultural and Biological Sciences&quot;,
      &quot;Chemical Engineering&quot;, &quot;Chemistry&quot;,  &quot;Computer Science&quot;, &quot;Decision Sciences&quot;,
      &quot;Earth and Planetary Sciences&quot;, &quot;Energy&quot;, &quot;Engineering&quot;, &quot;Environmental Science&quot;,
      &quot;Immunology and Microbiology&quot;, &quot;Materials Science&quot;, &quot;Mathematics&quot;, &quot;Neuroscience&quot;, 
      &quot;Physics and Astronomy&quot; ) ~ &quot;STEM&quot;,
    c(&quot;Dentistry&quot;, &quot;Health Professions&quot;, &quot;Medicine&quot;) ~ &quot;Medicine&quot;,
    c(&quot;Business, Management and Accounting&quot;, &quot;Economics, Econometrics and Finance&quot;,
      &quot;Psychology&quot;, &quot;Social Sciences&quot;) ~ &quot;Social sciences&quot;))</code></pre>
<p>Rename the columns neatly:</p>
<pre class="r"><code>prof_panel_tidy &lt;- prof_panel_coa %&gt;%
  select(-c(cited_by_before_2012, cited_by_total_oa, cited_by_total_oa_l, dupl, dupl_l, 
           coa_cited_by_before_2012, coa_count_pubs_before_2012, coa_cited_by_before_2012_l,
           coa_count_pubs_before_2012, prof_tot_count_pubs_total_oa, prof_tot_cited_by_total_oa,
           prof_tot_cited_by_before_2012, prof_tot_count_pubs_before_2012  ))%&gt;%
  rename(
    online_news = attn_news_by,
    online_news_total = attn_news_by_total,
    online_news_l = attn_news_by_l,
    online_news_total_l = attn_news_by_total_l,
    blogs = attn_blogs_by,
    blogs_total = attn_blogs_by_total,
    blogs_l = attn_blogs_by_l,
    blogs_total_l = attn_blogs_by_total_l,
    twitter = attn_twitter_by,
    twitter_total = attn_twitter_by_total,
    twitter_l = attn_twitter_by_l,
    twitter_total_l = attn_twitter_by_total_l,
    grant_veni = veni,
    grant_veni_l = veni_l,
    grant_vidi = vidi,
    grant_vidi_l = vidi_l,    
    grant_vici = vici,
    grant_vici_l = vici_l,
    grant_stevin = stevin,
    grant_stevin_l = stevin_l,
    grant_spinoza = spinoza,
    grant_spinoza_l = spinoza_l,
    grant_starting = starting,
    grant_starting_l = starting_l,
    grant_advanced = advanced,
    grant_advanced_l = advanced_l,
    grant_consolidator = consolidator,
    grant_consolidator_l = consolidator_l,
    grant_synergy = synergy,
    grant_synergy_l = synergy_l,
    coa_online_news = coa_attn_news_by,
    coa_blogs = coa_attn_blog_by,
    coa_twitter = coa_attn_twitter_by,
    coa_online_news_total = coa_attn_news_by_total,
    coa_blogs_total = coa_attn_blog_by_total,
    coa_twitter_total = coa_attn_twitter_by_total,
    coa_online_news_l = coa_attn_news_by_l,
    coa_blogs_l = coa_attn_blog_by_l,
    coa_twitter_l = coa_attn_twitter_by_l,
    coa_online_news_total_l = coa_attn_news_by_total_l,
    coa_blogs_total_l = coa_attn_blog_by_total_l,
    coa_twitter_total_l = coa_attn_twitter_by_total_l,
    coa_tot_count_pubs = prof_tot_count_pubs, 
    coa_tot_cited_by = prof_tot_cited_by,
    coa_tot_count_pubs_total = prof_tot_count_pubs_total_all,
    coa_tot_cited_by_total = prof_tot_cited_by_total_all,
    coa_tot_online_news = prof_tot_coa_attn_news_by,
    coa_tot_blogs = prof_tot_coa_attn_blog_by,
    coa_tot_twitter = prof_tot_coa_attn_twitter_by,
    coa_tot_online_news_total = prof_tot_coa_attn_news_by_total,
    coa_tot_blogs_total = prof_tot_coa_attn_blog_by_total,
    coa_tot_twitter_total = prof_tot_coa_attn_twitter_by_total,
    coa_tot_unique_m = prof_tot_unique_coa_m,
    coa_tot_unique_w = prof_tot_unique_coa_w,
    coa_tot_unique_u = prof_tot_unique_coa_u,
    coa_tot_count_pubs_l = prof_tot_count_pubs_l, 
    coa_tot_cited_by_l = prof_tot_cited_by_l,
    coa_tot_count_pubs_total_l = prof_tot_count_pubs_total_all_l,
    coa_tot_cited_by_total_l = prof_tot_cited_by_total_all_l,
    coa_tot_online_news_l = prof_tot_coa_attn_news_by_l,
    coa_tot_blogs_l = prof_tot_coa_attn_blog_by_l,
    coa_tot_twitter_l = prof_tot_coa_attn_twitter_by_l,
    coa_tot_online_news_total_l = prof_tot_coa_attn_news_by_total_l,
    coa_tot_blogs_total_l = prof_tot_coa_attn_blog_by_total_l,
    coa_tot_twitter_total_l = prof_tot_coa_attn_twitter_by_total_l,
    coa_tot_unique_m_l = prof_tot_unique_coa_m_l,
    coa_tot_unique_w_l = prof_tot_unique_coa_w_l,
    coa_tot_unique_u_l = prof_tot_unique_coa_u_l,
    news_national = lexis_national,
    news_regional = lexis_regional,
    news_intl = lexis_intl,
    news = lexis_all,
    news_national_total = lexis_national_total,
    news_regional_total = lexis_regional_total,
    news_intl_total = lexis_intl_total,
    news_total = lexis_all_total,
    news_national_l = lexis_national_l,
    news_regional_l = lexis_regional_l,
    news_intl_l = lexis_intl_l,
    news_l = lexis_all_l,
    news_national_total_l = lexis_national_total_l,
    news_regional_total_l = lexis_regional_total_l,
    news_intl_total_l = lexis_intl_total_l,
    news_total_l = lexis_all_total_l)</code></pre>
<p>Select relevant columns and tidy everything up:</p>
<pre class="r"><code>prof_panel_tidy &lt;- prof_panel_tidy %&gt;%
  # but not 2024
  filter(year &lt; 2024 &amp; !is.na(year))

# tidy up mentions
prof_panel_tidy$online_news &lt;- prof_panel_tidy$online_news + prof_panel_tidy$blogs
prof_panel_tidy$online_news_l &lt;- prof_panel_tidy$online_news_l + prof_panel_tidy$blogs_l
prof_panel_tidy$online_news_total_l &lt;- prof_panel_tidy$online_news_total_l + prof_panel_tidy$blogs_total_l

# coauthors this year
prof_panel_tidy$coa_online_news &lt;- prof_panel_tidy$coa_online_news + prof_panel_tidy$coa_blogs
prof_panel_tidy$coa_online_news_l &lt;- prof_panel_tidy$coa_online_news_l + prof_panel_tidy$coa_blogs_l
prof_panel_tidy$coa_online_news_total &lt;- prof_panel_tidy$coa_online_news_total + prof_panel_tidy$coa_blogs_total
prof_panel_tidy$coa_online_news_total_l &lt;- prof_panel_tidy$coa_online_news_total_l + prof_panel_tidy$coa_blogs_total_l

# all coauthors up until now
prof_panel_tidy$coa_tot_online_news &lt;- prof_panel_tidy$coa_tot_online_news + prof_panel_tidy$coa_tot_blogs
prof_panel_tidy$coa_tot_online_news_l &lt;- prof_panel_tidy$coa_tot_online_news_l + prof_panel_tidy$coa_tot_blogs_l
prof_panel_tidy$coa_tot_online_news_total &lt;- prof_panel_tidy$coa_tot_online_news_total + prof_panel_tidy$coa_tot_blogs_total
prof_panel_tidy$coa_tot_online_news_total_l &lt;- prof_panel_tidy$coa_tot_online_news_total_l + prof_panel_tidy$coa_tot_blogs_total_l

# get groups per years since entry
prof_panel_tidy$entry_batch &lt;- cut(prof_panel_tidy$years_since_first_pub, breaks = seq(0, 50, by=10))
prof_panel_tidy$years_since_entry &lt;- paste(&quot;up to&quot;, str_remove(str_split_i(as.character(prof_panel_tidy$entry_batch), &quot;,&quot;, 2),&quot;]&quot;))</code></pre>
<p>Alternatively, leave only those professors for whom we actually have
lexis data:</p>
<pre class="r"><code># ones we collected before 20.3. in the morning 
lexis_info &lt;- file.info(list.files(path = &quot;../lexis_crawl/downloads/zipfiles&quot;,
                                   pattern=&quot;*.zip&quot;,
                                   full.names = T))
lexis_rel_list &lt;- filter(lexis_info,
                         mtime &lt;= &quot;2024-03-20 8:55:00&quot;)

lexis_rel_list$profile_id &lt;- str_remove(str_remove(rownames(lexis_rel_list), &quot;../lexis_crawl/downloads/zipfiles/&quot;), &quot;.zip&quot;)

# minus ones that are incomplete
missing_indices &lt;- read_csv(&quot;../lexis_crawl/missing_indices.csv&quot;)

lexis_list &lt;- filter(lexis_rel_list, ! profile_id %in% missing_indices$profile_id)

prof_panel_filter &lt;- filter(prof_panel_tidy,
                            str_remove(profile_id, &quot;https://www.narcis.nl/person/RecordID/&quot;) %in% lexis_list$profile_id)</code></pre>
</div>
<div id="simple-descriptives" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Simple
descriptives</h1>
<p>How many profs?</p>
<pre class="r"><code>length(unique(prof_panel_filter$profile_id))</code></pre>
<pre><code>## [1] 3226</code></pre>
<p>Professors per field and subfield?</p>
<pre class="r"><code>print.data.frame(prof_panel_filter %&gt;%
  distinct(profile_id, .keep_all = TRUE)%&gt;%
  filter(!is.na(general_field))%&gt;%
  group_by(general_field)%&gt;%
  summarise(n = n())%&gt;%
  arrange(-n))</code></pre>
<pre><code>##       general_field    n
## 1   Social sciences 1220
## 2              STEM 1056
## 3          Medicine  764
## 4 Arts &amp; Humanities  184</code></pre>
<div id="correlations" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Correlations</h2>
<p>A correlation matrix:</p>
<pre class="r"><code>round(cor(prof_panel_filter[c(&quot;count_pubs&quot;, &quot;cited_by&quot;,
                              &quot;online_news&quot;, &quot;news&quot;, &quot;twitter&quot;,
                              &quot;coa_count_pubs&quot;, &quot;coa_cited_by&quot;,
                              &quot;coa_online_news&quot;, &quot;coa_twitter&quot;)],
          use=&quot;complete.obs&quot;), 2)</code></pre>
<pre><code>##                 count_pubs cited_by online_news news twitter coa_count_pubs coa_cited_by coa_online_news coa_twitter
## count_pubs            1.00     0.60        0.35 0.06    0.24           0.45         0.47            0.34        0.33
## cited_by              0.60     1.00        0.48 0.09    0.31           0.34         0.51            0.40        0.42
## online_news           0.35     0.48        1.00 0.18    0.39           0.21         0.34            0.60        0.48
## news                  0.06     0.09        0.18 1.00    0.09           0.05         0.07            0.09        0.09
## twitter               0.24     0.31        0.39 0.09    1.00           0.13         0.21            0.39        0.39
## coa_count_pubs        0.45     0.34        0.21 0.05    0.13           1.00         0.86            0.21        0.19
## coa_cited_by          0.47     0.51        0.34 0.07    0.21           0.86         1.00            0.35        0.34
## coa_online_news       0.34     0.40        0.60 0.09    0.39           0.21         0.35            1.00        0.79
## coa_twitter           0.33     0.42        0.48 0.09    0.39           0.19         0.34            0.79        1.00</code></pre>
<pre class="r"><code>round(cor(prof_panel_filter[c(&quot;count_pubs&quot;, &quot;count_pubs_total_l&quot;,
                              &quot;cited_by&quot;, &quot;cited_by_total_all_l&quot;,
                              &quot;online_news&quot;, &quot;news&quot;, &quot;twitter&quot;,
                              &quot;coa_count_pubs&quot;, &quot;coa_cited_by&quot;,
                              &quot;coa_online_news&quot;, &quot;coa_twitter&quot;)],
          use=&quot;complete.obs&quot;), 2)</code></pre>
<pre><code>##                      count_pubs count_pubs_total_l cited_by cited_by_total_all_l online_news news twitter
## count_pubs                 1.00               0.62     0.61                 0.50        0.37 0.06    0.25
## count_pubs_total_l         0.62               1.00     0.71                 0.76        0.36 0.09    0.22
## cited_by                   0.61               0.71     1.00                 0.83        0.48 0.09    0.31
## cited_by_total_all_l       0.50               0.76     0.83                 1.00        0.43 0.08    0.27
## online_news                0.37               0.36     0.48                 0.43        1.00 0.18    0.39
## news                       0.06               0.09     0.09                 0.08        0.18 1.00    0.09
## twitter                    0.25               0.22     0.31                 0.27        0.39 0.09    1.00
## coa_count_pubs             0.43               0.33     0.34                 0.31        0.21 0.05    0.13
## coa_cited_by               0.48               0.42     0.50                 0.44        0.34 0.07    0.21
## coa_online_news            0.36               0.32     0.40                 0.35        0.60 0.10    0.39
## coa_twitter                0.34               0.30     0.42                 0.34        0.48 0.10    0.38
##                      coa_count_pubs coa_cited_by coa_online_news coa_twitter
## count_pubs                     0.43         0.48            0.36        0.34
## count_pubs_total_l             0.33         0.42            0.32        0.30
## cited_by                       0.34         0.50            0.40        0.42
## cited_by_total_all_l           0.31         0.44            0.35        0.34
## online_news                    0.21         0.34            0.60        0.48
## news                           0.05         0.07            0.10        0.10
## twitter                        0.13         0.21            0.39        0.38
## coa_count_pubs                 1.00         0.88            0.21        0.20
## coa_cited_by                   0.88         1.00            0.35        0.34
## coa_online_news                0.21         0.35            1.00        0.79
## coa_twitter                    0.20         0.34            0.79        1.00</code></pre>
</div>
<div id="vifs" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> VIFs</h2>
<div id="news-models" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> News models</h3>
<pre class="r"><code>test_vif &lt;- plm(news~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model=&quot;pooling&quot;)
vif(test_vif)</code></pre>
<pre><code>##                              GVIF Df GVIF^(1/(2*Df))
## count_pubs               1.700220  1        1.303925
## cited_by                 2.507814  1        1.583608
## inferred_gender          1.049881  1        1.024637
## coa_tot_count_pubs_l     3.103550  1        1.761689
## coa_tot_cited_by_total_l 4.198330  1        2.048983
## coa_online_news_total_l  4.135992  1        2.033714
## coa_twitter_total_l      4.448592  1        2.109169
## as.factor(general_field) 1.229824  3        1.035080</code></pre>
<pre class="r"><code>test_vif &lt;- plm(news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model=&quot;pooling&quot;)
vif(test_vif)</code></pre>
<pre><code>##                              GVIF Df GVIF^(1/(2*Df))
## count_pubs_total_l       2.638342  1        1.624297
## cited_by_total_all_l     3.165196  1        1.779100
## inferred_gender          1.077226  1        1.037895
## coa_tot_count_pubs_l     3.214243  1        1.792831
## coa_tot_cited_by_total_l 4.397953  1        2.097130
## coa_online_news_total_l  4.121912  1        2.030249
## coa_twitter_total_l      4.345548  1        2.084598
## as.factor(general_field) 1.206829  3        1.031829</code></pre>
<p>Online news</p>
<pre class="r"><code>test_vif &lt;- plm(online_news~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model=&quot;pooling&quot;)
vif(test_vif)</code></pre>
<pre><code>##                              GVIF Df GVIF^(1/(2*Df))
## count_pubs               1.700220  1        1.303925
## cited_by                 2.507814  1        1.583608
## inferred_gender          1.049881  1        1.024637
## coa_tot_count_pubs_l     3.103550  1        1.761689
## coa_tot_cited_by_total_l 4.198330  1        2.048983
## coa_online_news_total_l  4.135992  1        2.033714
## coa_twitter_total_l      4.448592  1        2.109169
## as.factor(general_field) 1.229824  3        1.035080</code></pre>
<pre class="r"><code>test_vif &lt;- plm(online_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model=&quot;pooling&quot;)
vif(test_vif)</code></pre>
<pre><code>##                              GVIF Df GVIF^(1/(2*Df))
## count_pubs_total_l       2.638342  1        1.624297
## cited_by_total_all_l     3.165196  1        1.779100
## inferred_gender          1.077226  1        1.037895
## coa_tot_count_pubs_l     3.214243  1        1.792831
## coa_tot_cited_by_total_l 4.397953  1        2.097130
## coa_online_news_total_l  4.121912  1        2.030249
## coa_twitter_total_l      4.345548  1        2.084598
## as.factor(general_field) 1.206829  3        1.031829</code></pre>
<p>Twitter</p>
<pre class="r"><code>test_vif &lt;- plm(twitter~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model=&quot;pooling&quot;)
vif(test_vif)</code></pre>
<pre><code>##                              GVIF Df GVIF^(1/(2*Df))
## count_pubs               1.700220  1        1.303925
## cited_by                 2.507814  1        1.583608
## inferred_gender          1.049881  1        1.024637
## coa_tot_count_pubs_l     3.103550  1        1.761689
## coa_tot_cited_by_total_l 4.198330  1        2.048983
## coa_online_news_total_l  4.135992  1        2.033714
## coa_twitter_total_l      4.448592  1        2.109169
## as.factor(general_field) 1.229824  3        1.035080</code></pre>
<pre class="r"><code>test_vif &lt;- plm(twitter~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model=&quot;pooling&quot;)
vif(test_vif)</code></pre>
<pre><code>##                              GVIF Df GVIF^(1/(2*Df))
## count_pubs_total_l       2.638342  1        1.624297
## cited_by_total_all_l     3.165196  1        1.779100
## inferred_gender          1.077226  1        1.037895
## coa_tot_count_pubs_l     3.214243  1        1.792831
## coa_tot_cited_by_total_l 4.397953  1        2.097130
## coa_online_news_total_l  4.121912  1        2.030249
## coa_twitter_total_l      4.345548  1        2.084598
## as.factor(general_field) 1.206829  3        1.031829</code></pre>
</div>
</div>
<div id="descriprives" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Descriprives</h2>
<p>And some descriptives:</p>
<pre class="r"><code>psych::describe(prof_panel_filter[c(&quot;count_pubs&quot;, &quot;cited_by&quot;,
                              &quot;online_news&quot;, &quot;news&quot;, &quot;twitter&quot;,
                              &quot;coa_count_pubs&quot;, &quot;coa_cited_by&quot;,
                              &quot;coa_online_news&quot;, &quot;coa_twitter&quot;)])</code></pre>
<pre><code>##                 vars     n    mean      sd median trimmed    mad min    max  range  skew kurtosis    se
## count_pubs         1 93110    8.41   12.65    5.0    6.45   5.93   0   2054   2054 49.56  7420.78  0.04
## cited_by           2 36318  554.91  967.24  255.0  366.32 341.00   1  26602  26601  7.09   104.46  5.08
## online_news        3 40314    7.71   35.00    0.0    1.67   0.00   0   2165   2165 17.25   598.46  0.17
## news               4 93110    1.52    5.31    0.0    0.44   0.00   0    465    465 20.95  1321.29  0.02
## twitter            5 40282   36.17  210.66    0.0    4.80   0.00   0   9013   9013 17.18   423.03  1.05
## coa_count_pubs     6 32866   88.96  275.83   30.0   41.68  34.10   1   8914   8913 10.61   165.64  1.52
## coa_cited_by       7 32866 2977.54 9766.71  499.5 1049.17 713.87   0 264007 264007  8.66   105.97 53.87
## coa_online_news    8 32866   22.40  121.09    0.0    2.76   0.00   0   5829   5829 15.98   425.09  0.67
## coa_twitter        9 32866  217.78 1289.91    6.0   39.63   8.90   0  60396  60396 22.30   724.38  7.12</code></pre>
<p>Get some panel statistics:</p>
<pre class="r"><code>xtsum::xtsum(
  prof_panel_filter,
  variables = c(&quot;count_pubs&quot;, &quot;cited_by&quot;,
                &quot;online_news&quot;, &quot;news&quot;, &quot;twitter&quot;,
                &quot;coa_count_pubs&quot;, &quot;coa_cited_by&quot;,
                &quot;coa_online_news&quot;, &quot;coa_twitter&quot;),
  id = &quot;profile_id&quot;,
  t = &quot;year&quot;,
  na.rm = TRUE,
  return.data.frame = FALSE,
  dec = 2
)</code></pre>
<table class=" lightable-classic" style="font-family: &quot;Arial Narrow&quot;, &quot;Source Sans Pro&quot;, sans-serif; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:left;">
Dim
</th>
<th style="text-align:left;">
Mean
</th>
<th style="text-align:left;">
SD
</th>
<th style="text-align:left;">
Min
</th>
<th style="text-align:left;">
Max
</th>
<th style="text-align:left;">
Observations
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
___________
</td>
<td style="text-align:left;">
_________
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
count_pubs
</td>
<td style="text-align:left;">
overall
</td>
<td style="text-align:left;">
8.41
</td>
<td style="text-align:left;">
12.65
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
2054
</td>
<td style="text-align:left;">
N = 93110
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
between
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
6.49
</td>
<td style="text-align:left;">
0.08
</td>
<td style="text-align:left;">
102.55
</td>
<td style="text-align:left;">
n = 3226
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
within
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
10.76
</td>
<td style="text-align:left;">
-93.13
</td>
<td style="text-align:left;">
1997.3
</td>
<td style="text-align:left;">
T = 28.86
</td>
</tr>
<tr>
<td style="text-align:left;">
___________
</td>
<td style="text-align:left;">
_________
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
cited_by
</td>
<td style="text-align:left;">
overall
</td>
<td style="text-align:left;">
554.91
</td>
<td style="text-align:left;">
967.24
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
26602
</td>
<td style="text-align:left;">
N = 36318
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
between
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
881.94
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
15877.33
</td>
<td style="text-align:left;">
n = 3169
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
within
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
367.43
</td>
<td style="text-align:left;">
-8272.42
</td>
<td style="text-align:left;">
18949.83
</td>
<td style="text-align:left;">
T = 11.46
</td>
</tr>
<tr>
<td style="text-align:left;">
___________
</td>
<td style="text-align:left;">
_________
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
online_news
</td>
<td style="text-align:left;">
overall
</td>
<td style="text-align:left;">
7.71
</td>
<td style="text-align:left;">
35
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
2165
</td>
<td style="text-align:left;">
N = 40314
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
between
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
20.63
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
382
</td>
<td style="text-align:left;">
n = 3217
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
within
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
27.92
</td>
<td style="text-align:left;">
-363.29
</td>
<td style="text-align:left;">
1794.86
</td>
<td style="text-align:left;">
T = 12.53
</td>
</tr>
<tr>
<td style="text-align:left;">
___________
</td>
<td style="text-align:left;">
_________
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
news
</td>
<td style="text-align:left;">
overall
</td>
<td style="text-align:left;">
1.52
</td>
<td style="text-align:left;">
5.31
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
465
</td>
<td style="text-align:left;">
N = 93110
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
between
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
2.82
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
40
</td>
<td style="text-align:left;">
n = 3226
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
within
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
4.61
</td>
<td style="text-align:left;">
-21.35
</td>
<td style="text-align:left;">
445.56
</td>
<td style="text-align:left;">
T = 28.86
</td>
</tr>
<tr>
<td style="text-align:left;">
___________
</td>
<td style="text-align:left;">
_________
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
twitter
</td>
<td style="text-align:left;">
overall
</td>
<td style="text-align:left;">
36.17
</td>
<td style="text-align:left;">
210.66
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
9013
</td>
<td style="text-align:left;">
N = 40282
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
between
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
130.62
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
2650.54
</td>
<td style="text-align:left;">
n = 3217
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
within
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
163.59
</td>
<td style="text-align:left;">
-2460.37
</td>
<td style="text-align:left;">
7557.94
</td>
<td style="text-align:left;">
T = 12.52
</td>
</tr>
<tr>
<td style="text-align:left;">
___________
</td>
<td style="text-align:left;">
_________
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
coa_count_pubs
</td>
<td style="text-align:left;">
overall
</td>
<td style="text-align:left;">
88.96
</td>
<td style="text-align:left;">
275.83
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
8914
</td>
<td style="text-align:left;">
N = 32866
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
between
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
142.98
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
1733.83
</td>
<td style="text-align:left;">
n = 3173
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
within
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
230.81
</td>
<td style="text-align:left;">
-1448.87
</td>
<td style="text-align:left;">
8220.3
</td>
<td style="text-align:left;">
T = 10.36
</td>
</tr>
<tr>
<td style="text-align:left;">
___________
</td>
<td style="text-align:left;">
_________
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
coa_cited_by
</td>
<td style="text-align:left;">
overall
</td>
<td style="text-align:left;">
2977.54
</td>
<td style="text-align:left;">
9766.71
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
264007
</td>
<td style="text-align:left;">
N = 32866
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
between
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
6015.53
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
79400.17
</td>
<td style="text-align:left;">
n = 3173
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
within
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
7390.71
</td>
<td style="text-align:left;">
-61128.87
</td>
<td style="text-align:left;">
221034.38
</td>
<td style="text-align:left;">
T = 10.36
</td>
</tr>
<tr>
<td style="text-align:left;">
___________
</td>
<td style="text-align:left;">
_________
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
coa_online_news
</td>
<td style="text-align:left;">
overall
</td>
<td style="text-align:left;">
22.4
</td>
<td style="text-align:left;">
121.09
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
5829
</td>
<td style="text-align:left;">
N = 32866
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
between
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
68.22
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
1439.83
</td>
<td style="text-align:left;">
n = 3173
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
within
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
96.73
</td>
<td style="text-align:left;">
-1304.43
</td>
<td style="text-align:left;">
5328.15
</td>
<td style="text-align:left;">
T = 10.36
</td>
</tr>
<tr>
<td style="text-align:left;">
___________
</td>
<td style="text-align:left;">
_________
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;">
coa_twitter
</td>
<td style="text-align:left;">
overall
</td>
<td style="text-align:left;">
217.78
</td>
<td style="text-align:left;">
1289.91
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
60396
</td>
<td style="text-align:left;">
N = 32866
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
between
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
640.95
</td>
<td style="text-align:left;">
0
</td>
<td style="text-align:left;">
10829.17
</td>
<td style="text-align:left;">
n = 3173
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
within
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
1093
</td>
<td style="text-align:left;">
-10511.38
</td>
<td style="text-align:left;">
54027.62
</td>
<td style="text-align:left;">
T = 10.36
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="big-models" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Big models</h1>
<div id="citations" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Citations</h2>
<pre class="r"><code>citations_full &lt;- plm(cited_by ~ # professor publication variables
                  count_pubs_total_l + 
                  # gender
                  inferred_gender +
                  # attention variables
                  news_total_l + online_news_total_l + twitter_total_l +
                  # coauthor publication variables
                  coa_tot_count_pubs_l + coa_tot_cited_by_total_l +
                  # coauthor publication variables
                  coa_online_news_total_l + coa_twitter_total_l + 
                  # field and year controls
                  as.factor(general_field),
                 data = prof_panel_filter, model=&quot;pooling&quot;, index=c(&quot;profile_id&quot;, &quot;year&quot;)) 

# clustered SE
coeftest(citations_full, vcov=vcovHC(citations_full,type=&quot;HC0&quot;,cluster=&quot;group&quot;))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -2.2544e+02  3.3839e+01 -6.6622 2.745e-11 ***
## count_pubs_total_l                       2.4455e+00  2.9695e-01  8.2353 &lt; 2.2e-16 ***
## inferred_genderw                         2.3867e+01  2.0805e+01  1.1472   0.25132    
## news_total_l                            -3.4439e-01  2.1506e-01 -1.6014   0.10931    
## online_news_total_l                      1.2675e+00  2.8798e-01  4.4012 1.080e-05 ***
## twitter_total_l                          3.0391e-02  2.5732e-02  1.1810   0.23760    
## coa_tot_count_pubs_l                    -1.0181e-01  4.3787e-02 -2.3252   0.02007 *  
## coa_tot_cited_by_total_l                 2.9225e-03  3.6988e-04  7.9011 2.861e-15 ***
## coa_online_news_total_l                 -4.1492e-01  1.6357e-01 -2.5366   0.01120 *  
## coa_twitter_total_l                      6.0580e-02  2.6189e-02  2.3132   0.02072 *  
## as.factor(general_field)Medicine         3.2293e+02  3.4728e+01  9.2990 &lt; 2.2e-16 ***
## as.factor(general_field)Social sciences  1.0977e+02  2.0478e+01  5.3601 8.380e-08 ***
## as.factor(general_field)STEM             2.1832e+02  3.1248e+01  6.9867 2.874e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>round(summary(citations_full)$r.squared,3)</code></pre>
<pre><code>##    rsq adjrsq 
##  0.653  0.652</code></pre>
</div>
<div id="news" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> News</h2>
<p>This time period’s news given one’s total citations/publications,
past total attention, controlling for the field and year (Lexis sample
only). Pooled model with clustered SEs:</p>
<pre class="r"><code>news_full &lt;- plm(news ~ # professor publication variables
                  count_pubs_total_l + cited_by_total_all_l + 
                  # gender
                  inferred_gender +
                  # attention variables
                  online_news_total_l + twitter_total_l +
                  # coauthor publication variables
                  coa_tot_count_pubs_l + coa_tot_cited_by_total_l +
                  # coauthor publication variables
                  coa_online_news_total_l + coa_twitter_total_l + 
                  # field and year controls
                  as.factor(general_field),
                 data = prof_panel_filter, model=&quot;pooling&quot;, index=c(&quot;profile_id&quot;, &quot;year&quot;)) 

# clustered SE
coeftest(news_full, vcov=vcovHC(news_full,type=&quot;HC0&quot;,cluster=&quot;group&quot;))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.5873e+00  5.1759e-01  4.9987 5.804e-07 ***
## count_pubs_total_l                       3.2882e-03  8.8801e-04  3.7028 0.0002136 ***
## cited_by_total_all_l                    -1.0293e-05  2.2949e-05 -0.4485 0.6537727    
## inferred_genderw                        -4.0716e-01  1.9736e-01 -2.0630 0.0391227 *  
## online_news_total_l                      6.8863e-03  2.4154e-03  2.8510 0.0043608 ** 
## twitter_total_l                          1.3205e-04  1.7793e-04  0.7421 0.4580054    
## coa_tot_count_pubs_l                    -7.1027e-05  3.0704e-04 -0.2313 0.8170618    
## coa_tot_cited_by_total_l                -1.0301e-06  1.9893e-06 -0.5178 0.6045671    
## coa_online_news_total_l                 -3.9654e-04  4.4849e-04 -0.8842 0.3766136    
## coa_twitter_total_l                      7.2307e-06  6.2671e-05  0.1154 0.9081485    
## as.factor(general_field)Medicine        -1.3719e+00  5.5998e-01 -2.4498 0.0142977 *  
## as.factor(general_field)Social sciences  3.4000e-01  5.5722e-01  0.6102 0.5417521    
## as.factor(general_field)STEM            -1.2117e+00  5.5174e-01 -2.1962 0.0280880 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>round(summary(news_full)$r.squared,3)</code></pre>
<pre><code>##    rsq adjrsq 
##  0.027  0.027</code></pre>
</div>
<div id="online-news" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Online news</h2>
<p>This time period’s online news given one’s total
citations/publications, past total attention, controlling for the field
and year (Lexis sample only). Pooled model with clustered SEs:</p>
<pre class="r"><code>online_news_full &lt;- plm(online_news~ # professor publication variables
                  count_pubs_total_l + cited_by_total_all_l + 
                  # gender
                  inferred_gender +
                  # attention variables
                  news_total_l + twitter_total_l +
                  # coauthor publication variables
                  coa_tot_count_pubs_l + coa_tot_cited_by_total_l +
                  # coauthor publication variables
                  coa_online_news_total_l + coa_twitter_total_l + 
                  # field and year controls
                  as.factor(general_field),
                 data = prof_panel_filter, model=&quot;pooling&quot;, index=c(&quot;profile_id&quot;, &quot;year&quot;)) 

# clustered SE
coeftest(online_news_full, vcov=vcovHC(online_news_full,type=&quot;HC0&quot;,cluster=&quot;group&quot;))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -2.7857e+00  6.5687e-01 -4.2408 2.234e-05 ***
## count_pubs_total_l                       6.6834e-03  4.3945e-03  1.5209 0.1283036    
## cited_by_total_all_l                     8.0918e-04  1.6267e-04  4.9743 6.586e-07 ***
## inferred_genderw                         2.3242e+00  7.0950e-01  3.2758 0.0010549 ** 
## news_total_l                             3.6533e-02  9.4474e-03  3.8670 0.0001104 ***
## twitter_total_l                          5.5320e-03  1.8522e-03  2.9867 0.0028222 ** 
## coa_tot_count_pubs_l                    -2.4677e-03  1.9259e-03 -1.2813 0.2000839    
## coa_tot_cited_by_total_l                 6.4752e-05  1.8293e-05  3.5397 0.0004013 ***
## coa_online_news_total_l                  2.8915e-02  8.2260e-03  3.5151 0.0004403 ***
## coa_twitter_total_l                     -5.1287e-04  7.9681e-04 -0.6436 0.5198081    
## as.factor(general_field)Medicine         2.6969e+00  1.0196e+00  2.6452 0.0081687 ** 
## as.factor(general_field)Social sciences  8.0926e-01  4.8914e-01  1.6545 0.0980454 .  
## as.factor(general_field)STEM             2.6241e-01  8.2426e-01  0.3184 0.7502179    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>round(summary(online_news_full)$r.squared,3)</code></pre>
<pre><code>##    rsq adjrsq 
##  0.303  0.303</code></pre>
</div>
<div id="twitter" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Twitter</h2>
<p>This time period’s twitter attention given one’s total
citations/publications, past total attention, controlling for the field
and year (Lexis sample only). Pooled model with clustered SEs:</p>
<pre class="r"><code>twitter_full &lt;- plm(twitter~ # professor publication variables
                  count_pubs_total_l + cited_by_total_all_l + 
                  # gender
                  inferred_gender +
                  # attention variables
                  news_total_l + online_news_total_l +
                  # coauthor publication variables
                  coa_tot_count_pubs_l + coa_tot_cited_by_total_l +
                  # coauthor publication variables
                  coa_online_news_total_l + coa_twitter_total_l + 
                  # field and year controls
                  as.factor(general_field),
                 data = prof_panel_filter, model=&quot;pooling&quot;, index=c(&quot;profile_id&quot;, &quot;year&quot;)) 

# clustered SE
coeftest(twitter_full, vcov=vcovHC(twitter_full,type=&quot;HC0&quot;,cluster=&quot;group&quot;))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.71804794  5.27775996  0.5150  0.606557    
## count_pubs_total_l                      -0.03838329  0.04618347 -0.8311  0.405921    
## cited_by_total_all_l                     0.00301313  0.00143834  2.0949  0.036192 *  
## inferred_genderw                        -1.56925079  6.57378422 -0.2387  0.811329    
## news_total_l                            -0.01796217  0.05211300 -0.3447  0.730339    
## online_news_total_l                      0.40883654  0.09990224  4.0924 4.281e-05 ***
## coa_tot_count_pubs_l                     0.04802582  0.03065120  1.5668  0.117161    
## coa_tot_cited_by_total_l                -0.00022265  0.00015575 -1.4296  0.152851    
## coa_online_news_total_l                  0.11007470  0.06164449  1.7856  0.074168 .  
## coa_twitter_total_l                     -0.00272786  0.00537674 -0.5073  0.611917    
## as.factor(general_field)Medicine        23.07098643  7.97788248  2.8919  0.003832 ** 
## as.factor(general_field)Social sciences  6.09745942  3.09870973  1.9677  0.049107 *  
## as.factor(general_field)STEM             9.02523739  8.09927374  1.1143  0.265148    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>round(summary(twitter_full)$r.squared,3)</code></pre>
<pre><code>##    rsq adjrsq 
##  0.150  0.149</code></pre>
</div>
</div>
<div id="models-a-counts" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Models A: Counts</h1>
<div id="only-gender" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Only gender</h2>
<p>Publications and gender:</p>
<pre class="r"><code>gender_pubs &lt;- lm(count_pubs~inferred_gender, 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_pubs, vcov = vcovCL(gender_pubs, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                  Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)       8.74472    0.14752 59.2798 &lt; 2.2e-16 ***
## inferred_genderw -1.47043    0.25532 -5.7591 8.481e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Citations and gender:</p>
<pre class="r"><code>gender_cits &lt;- lm(cited_by~inferred_gender, 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_cits, vcov = vcovCL(gender_cits, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                  Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)       591.611     19.675 30.0696 &lt; 2.2e-16 ***
## inferred_genderw -149.931     32.624 -4.5957 4.328e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Conventional news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- lm(news~inferred_gender, 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       1.566278   0.054362 28.8120  &lt; 2e-16 ***
## inferred_genderw -0.227191   0.104108 -2.1823  0.02909 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Online News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- lm(online_news~inferred_gender, 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       7.74877    0.43954 17.6293   &lt;2e-16 ***
## inferred_genderw -0.16341    0.88663 -0.1843   0.8538    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- lm(twitter~inferred_gender, 
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       37.7171     2.8089 13.4278   &lt;2e-16 ***
## inferred_genderw  -6.2968     5.2372 -1.2023   0.2292    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="gender-and-fields" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> Gender and
fields</h2>
<p>Reference: “Arts &amp; Humanities”</p>
<p>Publications and gender:</p>
<pre class="r"><code>gender_pubs &lt;- lm(count_pubs~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_pubs, vcov = vcovCL(gender_pubs, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                         Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              4.39086    0.18511 23.7204 &lt; 2.2e-16 ***
## inferred_genderw                        -1.39731    0.23919 -5.8419 5.178e-09 ***
## as.factor(general_field)Medicine         8.53775    0.38739 22.0392 &lt; 2.2e-16 ***
## as.factor(general_field)Social sciences  1.89336    0.21287  8.8943 &lt; 2.2e-16 ***
## as.factor(general_field)STEM             4.29750    0.23478 18.3046 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Citations and gender:</p>
<pre class="r"><code>gender_cits &lt;- lm(cited_by~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_cits, vcov = vcovCL(gender_cits, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                         Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                               67.071     10.563  6.3496 2.185e-10 ***
## inferred_genderw                        -125.229     31.176 -4.0168 5.911e-05 ***
## as.factor(general_field)Medicine        1024.775     48.817 20.9921 &lt; 2.2e-16 ***
## as.factor(general_field)Social sciences  203.591     15.829 12.8622 &lt; 2.2e-16 ***
## as.factor(general_field)STEM             554.079     21.835 25.3754 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Conventional news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- lm(news~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                         Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              1.86522    0.24438  7.6324 2.326e-14 ***
## inferred_genderw                        -0.38263    0.10587 -3.6142 0.0003014 ***
## as.factor(general_field)Medicine        -0.52176    0.25101 -2.0787 0.0376504 *  
## as.factor(general_field)Social sciences  0.34034    0.25746  1.3219 0.1861991    
## as.factor(general_field)STEM            -0.68749    0.24959 -2.7545 0.0058789 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Online News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- lm(online_news~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                          Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                              0.298772   0.248437  1.2026   0.2291    
## inferred_genderw                        -0.089037   0.854351 -0.1042   0.9170    
## as.factor(general_field)Medicine        16.561210   1.165896 14.2047   &lt;2e-16 ***
## as.factor(general_field)Social sciences  2.765586   0.315052  8.7782   &lt;2e-16 ***
## as.factor(general_field)STEM             7.090139   0.618483 11.4637   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- lm(twitter~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                         Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                               2.2901     1.5800  1.4495    0.1472    
## inferred_genderw                         -5.0153     5.5399 -0.9053    0.3653    
## as.factor(general_field)Medicine         73.8257     7.4429  9.9190 &lt; 2.2e-16 ***
## as.factor(general_field)Social sciences  13.1192     1.8005  7.2866 3.237e-13 ***
## as.factor(general_field)STEM             36.6638     4.2141  8.7003 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="gender-and-prof-controls-not-lagged" class="section level2"
number="4.3">
<h2><span class="header-section-number">4.3</span> Gender and prof
controls (not lagged)</h2>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- lm(news~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.71246663  0.38369417  7.0693 1.585e-12 ***
## count_pubs                               0.00754549  0.00792128  0.9526  0.340819    
## cited_by                                 0.00080098  0.00019978  4.0093 6.102e-05 ***
## inferred_genderw                        -0.48359496  0.18817027 -2.5700  0.010174 *  
## as.factor(general_field)Medicine        -1.25859688  0.43476077 -2.8949  0.003795 ** 
## as.factor(general_field)Social sciences  0.44419265  0.41366227  1.0738  0.282917    
## as.factor(general_field)STEM            -1.10966220  0.41105433 -2.6996  0.006947 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.01670288</code></pre>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- lm(online_news~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                           Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -2.0868458  0.3791852 -5.5035 3.748e-08 ***
## count_pubs                               0.3019702  0.0783897  3.8522 0.0001173 ***
## cited_by                                 0.0162201  0.0024538  6.6102 3.891e-11 ***
## inferred_genderw                         2.3514700  0.6776938  3.4698 0.0005214 ***
## as.factor(general_field)Medicine        -3.1062349  1.7778562 -1.7472 0.0806146 .  
## as.factor(general_field)Social sciences -0.9869298  0.4911953 -2.0092 0.0445190 *  
## as.factor(general_field)STEM            -3.4361316  1.2508397 -2.7471 0.0060162 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_online_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.2403344</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- lm(twitter~count_pubs + cited_by + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                          Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -7.666169   2.474744 -3.0978  0.001951 ** 
## count_pubs                               1.378322   0.447027  3.0833  0.002049 ** 
## cited_by                                 0.061510   0.013356  4.6054 4.131e-06 ***
## inferred_genderw                         4.027638   5.569056  0.7232  0.469551    
## as.factor(general_field)Medicine        -3.242685   9.345438 -0.3470  0.728608    
## as.factor(general_field)Social sciences -1.333348   3.007220 -0.4434  0.657492    
## as.factor(general_field)STEM            -3.952471   7.487136 -0.5279  0.597571    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter)$adj.r.squared</code></pre>
<pre><code>## [1] 0.1044248</code></pre>
</div>
<div id="gender-and-prof-controls-lagged" class="section level2"
number="4.4">
<h2><span class="header-section-number">4.4</span> Gender and prof
controls (lagged)</h2>
<div id="news-1" class="section level3" number="4.4.1">
<h3><span class="header-section-number">4.4.1</span> News</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- lm(news~count_pubs_l + cited_by_l + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.72879936  0.39344236  6.9357 4.116e-12 ***
## count_pubs_l                             0.00703885  0.00905247  0.7776  0.436833    
## cited_by_l                               0.00083014  0.00020532  4.0431 5.287e-05 ***
## inferred_genderw                        -0.46653540  0.19514288 -2.3907  0.016820 *  
## as.factor(general_field)Medicine        -1.20027797  0.45007818 -2.6668  0.007661 ** 
## as.factor(general_field)Social sciences  0.48228027  0.42694573  1.1296  0.258651    
## as.factor(general_field)STEM            -1.07161979  0.42399443 -2.5274  0.011494 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.01556109</code></pre>
<p>Cumulative:</p>
<pre class="r"><code>gender_news &lt;- lm(news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.4306e+00  3.8078e-01  6.3832 1.758e-10 ***
## count_pubs_total_l                       3.1486e-03  8.1298e-04  3.8729 0.0001078 ***
## cited_by_total_all_l                     4.3541e-05  1.8918e-05  2.3015 0.0213694 *  
## inferred_genderw                        -3.3203e-01  1.9539e-01 -1.6993 0.0892695 .  
## as.factor(general_field)Medicine        -1.2219e+00  4.3393e-01 -2.8159 0.0048671 ** 
## as.factor(general_field)Social sciences  4.8806e-01  4.2098e-01  1.1594 0.2463185    
## as.factor(general_field)STEM            -1.1227e+00  4.1605e-01 -2.6984 0.0069700 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.01605226</code></pre>
</div>
<div id="online-news-1" class="section level3" number="4.4.2">
<h3><span class="header-section-number">4.4.2</span> Online news</h3>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- lm(online_news~count_pubs_l + cited_by_l + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                           Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -2.1271715  0.4303481 -4.9429 7.734e-07 ***
## count_pubs_l                             0.2814282  0.0850484  3.3090 0.0009372 ***
## cited_by_l                               0.0176752  0.0024971  7.0784 1.488e-12 ***
## inferred_genderw                         2.5406539  0.7481623  3.3959 0.0006849 ***
## as.factor(general_field)Medicine        -2.0731632  1.7597801 -1.1781 0.2387728    
## as.factor(general_field)Social sciences -0.8866004  0.4928380 -1.7990 0.0720326 .  
## as.factor(general_field)STEM            -3.1912318  1.2357091 -2.5825 0.0098127 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_online_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.2325328</code></pre>
<p>Cumulative:</p>
<pre class="r"><code>gender_online_news &lt;- lm(online_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.4306e+00  3.8078e-01  6.3832 1.758e-10 ***
## count_pubs_total_l                       3.1486e-03  8.1298e-04  3.8729 0.0001078 ***
## cited_by_total_all_l                     4.3541e-05  1.8918e-05  2.3015 0.0213694 *  
## inferred_genderw                        -3.3203e-01  1.9539e-01 -1.6993 0.0892695 .  
## as.factor(general_field)Medicine        -1.2219e+00  4.3393e-01 -2.8159 0.0048671 ** 
## as.factor(general_field)Social sciences  4.8806e-01  4.2098e-01  1.1594 0.2463185    
## as.factor(general_field)STEM            -1.1227e+00  4.1605e-01 -2.6984 0.0069700 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.01605226</code></pre>
</div>
<div id="twitter-1" class="section level3" number="4.4.3">
<h3><span class="header-section-number">4.4.3</span> Twitter</h3>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- lm(twitter~count_pubs_l + cited_by_l + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                          Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -9.411948   2.915475 -3.2283 0.0012466 ** 
## count_pubs_l                             1.728229   0.520266  3.3218 0.0008953 ***
## cited_by_l                               0.062041   0.013720  4.5221 6.144e-06 ***
## inferred_genderw                         4.330114   6.069872  0.7134 0.4756168    
## as.factor(general_field)Medicine         0.163397  10.278661  0.0159 0.9873168    
## as.factor(general_field)Social sciences -1.013066   3.293261 -0.3076 0.7583751    
## as.factor(general_field)STEM            -2.219235   8.166303 -0.2718 0.7858119    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter)$adj.r.squared</code></pre>
<pre><code>## [1] 0.09904429</code></pre>
<p>Cumulative:</p>
<pre class="r"><code>gender_twitter &lt;- lm(twitter~count_pubs_total_l + cited_by_total_all_l + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                           Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -6.4325950  4.4625479 -1.4415   0.14946    
## count_pubs_total_l                       0.0349110  0.0405171  0.8616   0.38889    
## cited_by_total_all_l                     0.0074391  0.0016020  4.6436 3.438e-06 ***
## inferred_genderw                         7.3727623  6.3366391  1.1635   0.24463    
## as.factor(general_field)Medicine        17.1432998  8.4165181  2.0369   0.04167 *  
## as.factor(general_field)Social sciences  3.1389801  2.9284942  1.0719   0.28378    
## as.factor(general_field)STEM             1.2746831  8.0903358  0.1576   0.87481    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter)$adj.r.squared</code></pre>
<pre><code>## [1] 0.07920386</code></pre>
</div>
</div>
<div id="prof-and-coauathor-controls" class="section level2"
number="4.5">
<h2><span class="header-section-number">4.5</span> Prof and coauathor
controls</h2>
<div id="conventional-news" class="section level3" number="4.5.1">
<h3><span class="header-section-number">4.5.1</span> Conventional
news</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news1 &lt;- lm(news~count_pubs + cited_by + inferred_gender + coa_count_pubs +
                    coa_cited_by + coa_online_news + coa_twitter + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news1, vcov = vcovCL(gender_news1, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.9112e+00  5.1211e-01  5.6847 1.322e-08 ***
## count_pubs                               1.0126e-03  7.9607e-03  0.1272  0.898780    
## cited_by                                 6.0729e-04  2.0259e-04  2.9977  0.002723 ** 
## inferred_genderw                        -5.3281e-01  1.8897e-01 -2.8195  0.004813 ** 
## coa_count_pubs                           4.2534e-04  4.5954e-04  0.9256  0.354668    
## coa_cited_by                             7.2777e-07  1.6028e-05  0.0454  0.963783    
## coa_online_news                          2.6509e-03  1.4001e-03  1.8934  0.058316 .  
## coa_twitter                              1.8031e-04  1.7867e-04  1.0092  0.312896    
## as.factor(general_field)Medicine        -1.4616e+00  5.5093e-01 -2.6530  0.007982 ** 
## as.factor(general_field)Social sciences  2.8491e-01  5.3966e-01  0.5280  0.597536    
## as.factor(general_field)STEM            -1.2758e+00  5.3409e-01 -2.3888  0.016908 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news1)$adj.r.squared</code></pre>
<pre><code>## [1] 0.0232059</code></pre>
<p>Lagged controls:</p>
<pre class="r"><code>gender_news2 &lt;- lm(news~count_pubs_l + cited_by_l + inferred_gender +
                    coa_count_pubs_l +
                    coa_cited_by_l + coa_online_news_l + coa_twitter_l + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news2, vcov = vcovCL(gender_news2, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.9048e+00  5.3280e-01  5.4519 5.025e-08 ***
## count_pubs_l                             7.3291e-03  9.2389e-03  0.7933 0.4276136    
## cited_by_l                               7.3469e-04  2.1528e-04  3.4127 0.0006442 ***
## inferred_genderw                        -5.0747e-01  1.9744e-01 -2.5703 0.0101657 *  
## coa_count_pubs_l                        -2.6931e-04  3.7477e-04 -0.7186 0.4723852    
## coa_cited_by_l                           9.7911e-06  1.4701e-05  0.6660 0.5054190    
## coa_online_news_l                        1.8523e-03  1.3049e-03  1.4194 0.1557811    
## coa_twitter_l                            2.5869e-06  1.0674e-04  0.0242 0.9806642    
## as.factor(general_field)Medicine        -1.4445e+00  5.8075e-01 -2.4874 0.0128741 *  
## as.factor(general_field)Social sciences  3.1481e-01  5.6609e-01  0.5561 0.5781338    
## as.factor(general_field)STEM            -1.2674e+00  5.6088e-01 -2.2596 0.0238519 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news2)$adj.r.squared</code></pre>
<pre><code>## [1] 0.01831934</code></pre>
<p>Coauthor totals:</p>
<pre class="r"><code>gender_news3 &lt;- lm(news~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news3, vcov = vcovCL(gender_news3, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.8956e+00  5.1191e-01  5.6565 1.558e-08 ***
## count_pubs                               3.8458e-03  7.7685e-03  0.4951  0.620568    
## cited_by                                 5.3784e-04  2.1987e-04  2.4462  0.014442 *  
## inferred_genderw                        -5.3775e-01  1.8924e-01 -2.8416  0.004492 ** 
## coa_tot_count_pubs                       1.7968e-04  2.6358e-04  0.6817  0.495459    
## coa_tot_cited_by_total                  -1.1314e-07  1.6665e-06 -0.0679  0.945871    
## coa_online_news_total                    4.0981e-04  4.7304e-04  0.8663  0.386322    
## coa_twitter_total                        9.0433e-05  6.3627e-05  1.4213  0.155239    
## as.factor(general_field)Medicine        -1.4558e+00  5.4990e-01 -2.6473  0.008118 ** 
## as.factor(general_field)Social sciences  2.8567e-01  5.3925e-01  0.5297  0.596289    
## as.factor(general_field)STEM            -1.2608e+00  5.3505e-01 -2.3565  0.018454 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news3)$adj.r.squared</code></pre>
<pre><code>## [1] 0.02234394</code></pre>
<p>All totals:</p>
<pre class="r"><code>gender_news4 &lt;- lm(news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news4, vcov = vcovCL(gender_news4, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.6023e+00  4.9776e-01  5.2279 1.726e-07 ***
## count_pubs_total_l                       2.7278e-03  8.7288e-04  3.1250   0.00178 ** 
## cited_by_total_all_l                     1.5010e-05  2.1265e-05  0.7059   0.48028    
## inferred_genderw                        -4.2798e-01  1.9747e-01 -2.1673   0.03022 *  
## coa_tot_count_pubs                       3.6409e-05  2.7549e-04  0.1322   0.89486    
## coa_tot_cited_by_total                   4.4873e-07  1.8508e-06  0.2424   0.80843    
## coa_online_news_total                    2.5435e-04  4.6765e-04  0.5439   0.58652    
## coa_twitter_total                        1.2080e-04  6.4291e-05  1.8790   0.06025 .  
## as.factor(general_field)Medicine        -1.4119e+00  5.4152e-01 -2.6073   0.00913 ** 
## as.factor(general_field)Social sciences  3.7477e-01  5.3780e-01  0.6969   0.48590    
## as.factor(general_field)STEM            -1.2005e+00  5.3150e-01 -2.2588   0.02390 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news4)$adj.r.squared</code></pre>
<pre><code>## [1] 0.02265159</code></pre>
</div>
<div id="online-news-2" class="section level3" number="4.5.2">
<h3><span class="header-section-number">4.5.2</span> Online news</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_online_news1 &lt;- lm(online_news~count_pubs + cited_by + inferred_gender + coa_count_pubs +
                    coa_cited_by + coa_online_news + coa_twitter + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_online_news1, vcov = vcovCL(gender_online_news1, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -0.85403361  0.36891046 -2.3150   0.02062 *  
## count_pubs                               0.08743459  0.06516884  1.3417   0.17971    
## cited_by                                 0.01007813  0.00182307  5.5281 3.262e-08 ***
## inferred_genderw                         1.27500791  0.51908653  2.4563   0.01404 *  
## coa_count_pubs                          -0.00865402  0.00549718 -1.5743   0.11544    
## coa_cited_by                             0.00035962  0.00020702  1.7371   0.08237 .  
## coa_online_news                          0.16737649  0.02228905  7.5094 6.095e-14 ***
## coa_twitter                             -0.00212934  0.00248035 -0.8585   0.39063    
## as.factor(general_field)Medicine        -1.38100693  1.37243710 -1.0062   0.31431    
## as.factor(general_field)Social sciences  0.10994094  0.41501450  0.2649   0.79108    
## as.factor(general_field)STEM            -1.49624983  0.86082800 -1.7382   0.08219 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_online_news1)$adj.r.squared</code></pre>
<pre><code>## [1] 0.4330209</code></pre>
<p>Lagged controls:</p>
<pre class="r"><code>gender_online_news2 &lt;- lm(online_news~count_pubs_l + cited_by_l + inferred_gender +
                    coa_count_pubs_l +
                    coa_cited_by_l + coa_online_news_l + coa_twitter_l + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_online_news2, vcov = vcovCL(gender_online_news2, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -1.43601948  0.39241868 -3.6594 0.0002532 ***
## count_pubs_l                             0.17871791  0.07020044  2.5458 0.0109071 *  
## cited_by_l                               0.01338915  0.00218213  6.1358 8.581e-10 ***
## inferred_genderw                         1.98837528  0.66522537  2.9890 0.0028010 ** 
## coa_count_pubs_l                        -0.01505404  0.00462414 -3.2555 0.0011331 ** 
## coa_cited_by_l                           0.00046469  0.00017325  2.6822 0.0073187 ** 
## coa_online_news_l                        0.09960132  0.02635038  3.7799 0.0001572 ***
## coa_twitter_l                           -0.00132021  0.00167444 -0.7884 0.4304429    
## as.factor(general_field)Medicine        -0.91882654  1.49394326 -0.6150 0.5385368    
## as.factor(general_field)Social sciences -0.11071411  0.48578092 -0.2279 0.8197182    
## as.factor(general_field)STEM            -1.60406458  1.04089480 -1.5410 0.1233169    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_online_news2)$adj.r.squared</code></pre>
<pre><code>## [1] 0.2928519</code></pre>
<p>Coauthor totals:</p>
<pre class="r"><code>gender_online_news3 &lt;- lm(online_news~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_online_news3, vcov = vcovCL(gender_online_news3, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -9.8536e-01  3.8277e-01 -2.5743 0.0100498 *  
## count_pubs                               1.2333e-01  6.1463e-02  2.0065 0.0448075 *  
## cited_by                                 7.9208e-03  1.8340e-03  4.3190 1.572e-05 ***
## inferred_genderw                         1.0478e+00  5.4388e-01  1.9266 0.0540398 .  
## coa_tot_count_pubs                      -2.8651e-03  1.8578e-03 -1.5422 0.1230370    
## coa_tot_cited_by_total                   4.4609e-05  1.7297e-05  2.5790 0.0099135 ** 
## coa_online_news_total                    3.7302e-02  1.0050e-02  3.7116 0.0002063 ***
## coa_twitter_total                       -4.1727e-05  1.1016e-03 -0.0379 0.9697839    
## as.factor(general_field)Medicine        -5.8899e-01  1.3317e+00 -0.4423 0.6582947    
## as.factor(general_field)Social sciences  3.3314e-01  4.2439e-01  0.7850 0.4324773    
## as.factor(general_field)STEM            -8.1622e-01  8.6008e-01 -0.9490 0.3426272    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_online_news3)$adj.r.squared</code></pre>
<pre><code>## [1] 0.3773083</code></pre>
<p>All totals:</p>
<pre class="r"><code>gender_online_news4 &lt;- lm(online_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_online_news4, vcov = vcovCL(gender_online_news4, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -5.9059e-01  4.2020e-01 -1.4055 0.1598861    
## count_pubs_total_l                       1.9350e-03  3.4495e-03  0.5610 0.5748273    
## cited_by_total_all_l                     8.1361e-04  1.4761e-04  5.5119  3.58e-08 ***
## inferred_genderw                         1.2903e+00  6.5321e-01  1.9753 0.0482380 *  
## coa_tot_count_pubs                      -2.0519e-03  1.8399e-03 -1.1152 0.2647556    
## coa_tot_cited_by_total                   4.7202e-05  1.7736e-05  2.6614 0.0077850 ** 
## coa_online_news_total                    3.5891e-02  1.0140e-02  3.5397 0.0004012 ***
## coa_twitter_total                        4.0392e-04  1.1208e-03  0.3604 0.7185496    
## as.factor(general_field)Medicine         1.5898e+00  8.6875e-01  1.8300 0.0672577 .  
## as.factor(general_field)Social sciences  9.6806e-01  3.5460e-01  2.7300 0.0063367 ** 
## as.factor(general_field)STEM            -1.6242e-01  6.6643e-01 -0.2437 0.8074505    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_online_news4)$adj.r.squared</code></pre>
<pre><code>## [1] 0.3640789</code></pre>
</div>
<div id="twitter-2" class="section level3" number="4.5.3">
<h3><span class="header-section-number">4.5.3</span> Twitter</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_twitter1 &lt;- lm(twitter~count_pubs + cited_by + inferred_gender + coa_count_pubs +
                    coa_cited_by + coa_online_news + coa_twitter + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_twitter1, vcov = vcovCL(gender_twitter1, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value Pr(&gt;|t|)   
## (Intercept)                             -2.98664739  2.92122613 -1.0224 0.306602   
## count_pubs                               0.57493309  0.43627741  1.3178 0.187575   
## cited_by                                 0.03346956  0.01099622  3.0437 0.002339 **
## inferred_genderw                        -0.58396700  5.97433062 -0.0977 0.922135   
## coa_count_pubs                          -0.02467436  0.05089799 -0.4848 0.627835   
## coa_cited_by                             0.00064919  0.00183541  0.3537 0.723565   
## coa_online_news                          0.38875644  0.19229917  2.0216 0.043224 * 
## coa_twitter                              0.02718103  0.01591489  1.7079 0.087665 . 
## as.factor(general_field)Medicine         5.25765384  8.13811795  0.6461 0.518250   
## as.factor(general_field)Social sciences  4.34632266  2.93150297  1.4826 0.138184   
## as.factor(general_field)STEM             7.67884282  6.57210191  1.1684 0.242654   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter1)$adj.r.squared</code></pre>
<pre><code>## [1] 0.1925985</code></pre>
<p>Lagged controls:</p>
<pre class="r"><code>gender_twitter2 &lt;- lm(twitter~count_pubs_l + cited_by_l + inferred_gender +
                    coa_count_pubs_l +
                    coa_cited_by_l + coa_online_news_l + coa_twitter_l + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_twitter2, vcov = vcovCL(gender_twitter2, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                           Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -5.9368118  3.2443626 -1.8299 0.0672773 .  
## count_pubs_l                             1.1884603  0.5081840  2.3386 0.0193607 *  
## cited_by_l                               0.0431340  0.0112737  3.8261 0.0001305 ***
## inferred_genderw                         0.6834033  6.6079768  0.1034 0.9176296    
## coa_count_pubs_l                        -0.0548935  0.0494747 -1.1095 0.2672117    
## coa_cited_by_l                           0.0013854  0.0018056  0.7673 0.4429331    
## coa_online_news_l                        0.4868993  0.1873361  2.5991 0.0093524 ** 
## coa_twitter_l                           -0.0054007  0.0099761 -0.5414 0.5882634    
## as.factor(general_field)Medicine         6.7986796  9.1937834  0.7395 0.4596175    
## as.factor(general_field)Social sciences  3.4540720  3.2894365  1.0500 0.2937039    
## as.factor(general_field)STEM             5.9577284  7.5796067  0.7860 0.4318617    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter2)$adj.r.squared</code></pre>
<pre><code>## [1] 0.1369793</code></pre>
<p>Coauthor totals:</p>
<pre class="r"><code>gender_twitter3 &lt;- lm(twitter~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_twitter3, vcov = vcovCL(gender_twitter3, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                           Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)                             -4.4897434  2.6388967 -1.7014  0.08888 . 
## count_pubs                               0.3794841  0.4729330  0.8024  0.42232   
## cited_by                                 0.0349231  0.0109166  3.1991  0.00138 **
## inferred_genderw                         0.2131103  5.9293714  0.0359  0.97133   
## coa_tot_count_pubs                       0.0383423  0.0278061  1.3789  0.16793   
## coa_tot_cited_by_total                  -0.0001715  0.0001248 -1.3742  0.16938   
## coa_online_news_total                    0.1271279  0.0689649  1.8434  0.06528 . 
## coa_twitter_total                        0.0053048  0.0055096  0.9628  0.33564   
## as.factor(general_field)Medicine         5.8562553  7.8900537  0.7422  0.45795   
## as.factor(general_field)Social sciences  3.0550172  3.0957655  0.9868  0.32373   
## as.factor(general_field)STEM             3.5774967  7.5268366  0.4753  0.63458   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter3)$adj.r.squared</code></pre>
<pre><code>## [1] 0.1675819</code></pre>
<p>All totals:</p>
<pre class="r"><code>gender_twitter4 &lt;- lm(twitter~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_twitter4, vcov = vcovCL(gender_twitter4, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value Pr(&gt;|t|)   
## (Intercept)                              4.30076010  4.97264772  0.8649 0.387110   
## count_pubs_total_l                      -0.06510136  0.05126522 -1.2699 0.204133   
## cited_by_total_all_l                     0.00438183  0.00137352  3.1902 0.001423 **
## inferred_genderw                        -1.97646724  6.61935217 -0.2986 0.765256   
## coa_tot_count_pubs                       0.04664462  0.02919413  1.5977 0.110112   
## coa_tot_cited_by_total                  -0.00016652  0.00012396 -1.3434 0.179164   
## coa_online_news_total                    0.12193120  0.06816712  1.7887 0.073672 . 
## coa_twitter_total                        0.00723304  0.00544539  1.3283 0.184094   
## as.factor(general_field)Medicine        18.09726486  7.96526775  2.2720 0.023092 * 
## as.factor(general_field)Social sciences  6.35797988  3.14017803  2.0247 0.042905 * 
## as.factor(general_field)STEM             8.08955884  8.17515712  0.9895 0.322412   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter4)$adj.r.squared</code></pre>
<pre><code>## [1] 0.1609522</code></pre>
</div>
</div>
<div id="cumulative-media-attention" class="section level2"
number="4.6">
<h2><span class="header-section-number">4.6</span> Cumulative media
attention?</h2>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- lm(news~news_l + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                          Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              0.603633   0.084749  7.1226 1.067e-12 ***
## news_l                                   0.690339   0.013291 51.9417 &lt; 2.2e-16 ***
## as.factor(general_field)Medicine        -0.130304   0.088951 -1.4649   0.14295    
## as.factor(general_field)Social sciences  0.180774   0.094536  1.9122   0.05585 .  
## as.factor(general_field)STEM            -0.179037   0.087957 -2.0355   0.04180 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.3580022</code></pre>
<p>Blog attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- lm(blogs~blogs_l + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                          Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             0.0384944  0.0068525  5.6176 1.950e-08 ***
## blogs_l                                 0.7228754  0.0324696 22.2631 &lt; 2.2e-16 ***
## as.factor(general_field)Medicine        0.7424044  0.0831220  8.9315 &lt; 2.2e-16 ***
## as.factor(general_field)Social sciences 0.1849360  0.0240696  7.6834 1.587e-14 ***
## as.factor(general_field)STEM            0.4924559  0.0438273 11.2363 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_online_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.5049034</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- lm(twitter~twitter_l + as.factor(general_field),
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                          Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              0.458534   0.112518  4.0752 4.607e-05 ***
## twitter_l                                0.623116   0.040552 15.3658 &lt; 2.2e-16 ***
## as.factor(general_field)Medicine        33.536767   4.121981  8.1361 4.209e-16 ***
## as.factor(general_field)Social sciences  5.970433   1.003996  5.9467 2.761e-09 ***
## as.factor(general_field)STEM            17.656882   2.032595  8.6869 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter)$adj.r.squared</code></pre>
<pre><code>## [1] 0.3770322</code></pre>
</div>
<div id="cumulative-media-attention-prof-and-coauthor-controls"
class="section level2" number="4.7">
<h2><span class="header-section-number">4.7</span> Cumulative media
attention, prof and coauthor controls</h2>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- lm(news~news_l + count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field) + as.factor(year), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              6.8097e-01  2.1369e-01  3.1867 0.0014403 ** 
## news_l                                   6.6510e-01  1.9004e-02 34.9981 &lt; 2.2e-16 ***
## count_pubs                               9.0307e-03  3.6143e-03  2.4986 0.0124737 *  
## cited_by                                 1.8223e-04  8.8389e-05  2.0616 0.0392503 *  
## inferred_genderw                        -1.7331e-01  8.4203e-02 -2.0583 0.0395719 *  
## coa_tot_count_pubs                      -5.5524e-06  1.1717e-04 -0.0474 0.9622037    
## coa_tot_cited_by_total                  -2.3130e-07  7.5391e-07 -0.3068 0.7589948    
## coa_online_news_total                    5.5688e-04  2.9924e-04  1.8610 0.0627556 .  
## coa_twitter_total                       -1.8961e-05  2.9268e-05 -0.6479 0.5170862    
## as.factor(general_field)Medicine        -5.0305e-01  2.1040e-01 -2.3909 0.0168107 *  
## as.factor(general_field)Social sciences  1.7154e-01  2.1553e-01  0.7959 0.4261063    
## as.factor(general_field)STEM            -4.5435e-01  2.0635e-01 -2.2019 0.0276827 *  
## as.factor(year)2013                      9.6940e-02  1.1571e-01  0.8378 0.4021461    
## as.factor(year)2014                      6.7121e-02  9.4165e-02  0.7128 0.4759719    
## as.factor(year)2015                     -3.9266e-03  9.5232e-02 -0.0412 0.9671108    
## as.factor(year)2016                      2.0064e-01  9.6944e-02  2.0697 0.0384890 *  
## as.factor(year)2017                      2.4268e-01  1.0586e-01  2.2925 0.0218814 *  
## as.factor(year)2018                      2.8575e-01  1.0343e-01  2.7627 0.0057360 ** 
## as.factor(year)2019                      4.1205e-01  1.1192e-01  3.6818 0.0002320 ***
## as.factor(year)2020                      7.2477e-01  1.7058e-01  4.2489 2.154e-05 ***
## as.factor(year)2021                      3.3107e-01  1.3751e-01  2.4076 0.0160652 *  
## as.factor(year)2022                      6.6664e-01  1.4107e-01  4.7256 2.304e-06 ***
## as.factor(year)2023                      1.0610e+00  3.0097e-01  3.5254 0.0004234 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.3195477</code></pre>
<p>Online news and gender:</p>
<pre class="r"><code>gender_online_news &lt;- lm(online_news~online_news_l + count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field) + as.factor(year), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -3.5654e+00  4.8254e-01 -7.3890 1.516e-13 ***
## online_news_l                            3.1471e-01  4.7255e-02  6.6599 2.784e-11 ***
## count_pubs                               1.6132e-01  5.0911e-02  3.1687 0.0015325 ** 
## cited_by                                 5.4304e-03  1.4296e-03  3.7987 0.0001457 ***
## inferred_genderw                         7.6125e-01  4.0379e-01  1.8853 0.0594027 .  
## coa_tot_count_pubs                      -2.8424e-03  1.4502e-03 -1.9601 0.0499977 *  
## coa_tot_cited_by_total                   2.8952e-05  1.3117e-05  2.2073 0.0273007 *  
## coa_online_news_total                    3.0635e-02  6.6230e-03  4.6255 3.751e-06 ***
## coa_twitter_total                       -2.7949e-04  7.8008e-04 -0.3583 0.7201337    
## as.factor(general_field)Medicine        -3.4580e-01  9.6390e-01 -0.3588 0.7197824    
## as.factor(general_field)Social sciences  3.0148e-01  3.0986e-01  0.9730 0.3305701    
## as.factor(general_field)STEM            -5.2487e-01  6.6410e-01 -0.7904 0.4293286    
## as.factor(year)2013                      7.5209e-01  1.1717e-01  6.4188 1.393e-10 ***
## as.factor(year)2014                      1.0764e+00  1.7396e-01  6.1877 6.178e-10 ***
## as.factor(year)2015                      1.3703e+00  2.1250e-01  6.4482 1.148e-10 ***
## as.factor(year)2016                      6.2726e+00  6.1662e-01 10.1725 &lt; 2.2e-16 ***
## as.factor(year)2017                      2.7597e+00  5.9441e-01  4.6427 3.452e-06 ***
## as.factor(year)2018                      2.0726e+00  6.3811e-01  3.2480 0.0011633 ** 
## as.factor(year)2019                      1.2530e+00  5.2629e-01  2.3809 0.0172765 *  
## as.factor(year)2020                      2.9036e+00  8.1314e-01  3.5708 0.0003564 ***
## as.factor(year)2021                      1.4489e+00  7.7796e-01  1.8624 0.0625500 .  
## as.factor(year)2022                      6.7918e+00  1.0140e+00  6.6977 2.152e-11 ***
## as.factor(year)2023                      4.2604e+00  8.7360e-01  4.8769 1.083e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_online_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.4344911</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- lm(twitter~twitter_l + count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                            Estimate  Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                             -4.6394e+00  1.4405e+00 -3.2206  0.001280 ** 
## twitter_l                                5.4913e-01  4.1197e-02 13.3296 &lt; 2.2e-16 ***
## count_pubs                               6.8284e-01  2.1755e-01  3.1388  0.001698 ** 
## cited_by                                 1.6357e-02  5.4973e-03  2.9755  0.002928 ** 
## inferred_genderw                         2.8724e-01  2.8377e+00  0.1012  0.919375    
## coa_tot_count_pubs                       1.8845e-02  1.3861e-02  1.3595  0.173994    
## coa_tot_cited_by_total                  -1.3630e-04  6.8415e-05 -1.9922  0.046352 *  
## coa_online_news_total                    5.5940e-02  3.4864e-02  1.6045  0.108606    
## coa_twitter_total                        2.6030e-03  3.2890e-03  0.7914  0.428701    
## as.factor(general_field)Medicine         2.6664e+00  3.8841e+00  0.6865  0.492413    
## as.factor(general_field)Social sciences  1.4749e+00  1.6161e+00  0.9126  0.361441    
## as.factor(general_field)STEM             2.4492e+00  3.9201e+00  0.6248  0.532127    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter)$adj.r.squared</code></pre>
<pre><code>## [1] 0.4014269</code></pre>
</div>
<div id="cumulative-media-attention-per-gender" class="section level2"
number="4.8">
<h2><span class="header-section-number">4.8</span> Cumulative media
attention per gender?</h2>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- lm(news~news_l*inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                          Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              0.654513   0.087334  7.4944 6.723e-14 ***
## news_l                                   0.681409   0.015260 44.6535 &lt; 2.2e-16 ***
## inferred_genderw                        -0.187444   0.041198 -4.5499 5.375e-06 ***
## as.factor(general_field)Medicine        -0.134331   0.089520 -1.5006   0.13347    
## as.factor(general_field)Social sciences  0.181864   0.095388  1.9066   0.05658 .  
## as.factor(general_field)STEM            -0.201802   0.089748 -2.2485   0.02454 *  
## news_l:inferred_genderw                  0.045550   0.028827  1.5801   0.11409    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.3583161</code></pre>
<p>Blog attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- lm(online_news~online_news_l*inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                          Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              0.245913   0.205480  1.1968    0.2314    
## online_news_l                            0.571515   0.049243 11.6060 &lt; 2.2e-16 ***
## inferred_genderw                        -0.365206   0.712080 -0.5129    0.6080    
## as.factor(general_field)Medicine         9.173778   0.951051  9.6459 &lt; 2.2e-16 ***
## as.factor(general_field)Social sciences  1.533106   0.193985  7.9032 2.793e-15 ***
## as.factor(general_field)STEM             3.855202   0.363442 10.6075 &lt; 2.2e-16 ***
## online_news_l:inferred_genderw           0.060223   0.091989  0.6547    0.5127    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_online_news)$adj.r.squared</code></pre>
<pre><code>## [1] 0.3004247</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- lm(twitter~twitter_l*inferred_gender + as.factor(general_field) +years_since_first_pub*inferred_gender,
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                                           Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)                              2.3349655  3.6997308  0.6311    0.5280    
## twitter_l                                0.6250553  0.0456219 13.7008 &lt; 2.2e-16 ***
## inferred_genderw                        -1.9362123  7.0064743 -0.2763    0.7823    
## as.factor(general_field)Medicine        33.6352085  4.1011603  8.2014 2.452e-16 ***
## as.factor(general_field)Social sciences  5.9532244  1.1324110  5.2571 1.471e-07 ***
## as.factor(general_field)STEM            17.3578913  2.0309923  8.5465 &lt; 2.2e-16 ***
## years_since_first_pub                   -0.0454679  0.1380764 -0.3293    0.7419    
## twitter_l:inferred_genderw              -0.0094469  0.0990622 -0.0954    0.9240    
## inferred_genderw:years_since_first_pub  -0.0122441  0.3034939 -0.0403    0.9678    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(gender_twitter)$adj.r.squared</code></pre>
<pre><code>## [1] 0.3770042</code></pre>
<p>the model above, watching out for totals etc. +</p>
<p>Network - coauthors - coauthors cites - coauthors attention - are
these for t or t-1</p>
<p>Share of coauthors in the high end of attention distribution.</p>
<ul>
<li>any attention (are you in the attention elite)</li>
<li>amount of attention</li>
<li>top 10%</li>
</ul>
<p>PUB TYPE - articles, books + book chapters - preprints? conf.
proceedings?</p>
</div>
</div>
<div id="models-b-any-attention" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Models B: Any
attention</h1>
<p>Get a binary variable denoting whether professor has gotten any
attention this year:</p>
<pre class="r"><code>prof_panel_filter$any_news &lt;- as.factor(ifelse(prof_panel_filter$news &gt; 0, 1, 0))
prof_panel_filter$any_news_l &lt;- as.factor(ifelse(prof_panel_filter$news_l &gt; 0, 1, 0))

prof_panel_filter$any_online_news &lt;- as.factor(ifelse(prof_panel_filter$online_news &gt; 0, 1, 0))
prof_panel_filter$any_online_news_l &lt;- as.factor(ifelse(prof_panel_filter$online_news_l &gt; 0, 1, 0))

prof_panel_filter$any_twitter &lt;- as.factor(ifelse(prof_panel_filter$twitter &gt; 0, 1, 0))
prof_panel_filter$any_twitter_l &lt;- as.factor(ifelse(prof_panel_filter$twitter_l &gt; 0, 1, 0))</code></pre>
<div id="gender-and-prof-controls" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Gender and prof
controls</h2>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- glm(any_news~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter,
                  family = &quot;binomial&quot;)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -2.1581e-02  1.0561e-01 -0.2043  0.838083    
## count_pubs                               8.0508e-03  2.1876e-03  3.6802  0.000233 ***
## cited_by                                 2.1458e-04  4.9353e-05  4.3478 1.375e-05 ***
## inferred_genderw                        -1.7820e-01  5.8776e-02 -3.0318  0.002431 ** 
## as.factor(general_field)Medicine        -7.0314e-01  1.2191e-01 -5.7677 8.037e-09 ***
## as.factor(general_field)Social sciences -6.3250e-02  1.1253e-01 -0.5621  0.574068    
## as.factor(general_field)STEM            -5.8181e-01  1.1617e-01 -5.0083 5.493e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_news)</code></pre>
<pre><code>##   McFadden 
## 0.01722182</code></pre>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- glm(any_online_news~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter,
                  family = &quot;binomial&quot;)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -2.52235713  0.13413345 -18.8048 &lt; 2.2e-16 ***
## count_pubs                               0.01559313  0.00299673   5.2034 1.957e-07 ***
## cited_by                                 0.00295955  0.00011409  25.9397 &lt; 2.2e-16 ***
## inferred_genderw                         0.30887242  0.05180194   5.9626 2.483e-09 ***
## as.factor(general_field)Medicine         1.27188173  0.14682718   8.6624 &lt; 2.2e-16 ***
## as.factor(general_field)Social sciences  0.88466625  0.13770392   6.4244 1.324e-10 ***
## as.factor(general_field)STEM             0.77930276  0.14244417   5.4709 4.477e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_online_news)</code></pre>
<pre><code>##  McFadden 
## 0.2785643</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- glm(any_twitter~count_pubs + cited_by + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter,
                  family = &quot;binomial&quot;)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -2.0979e+00  1.5109e-01 -13.8855 &lt; 2.2e-16 ***
## count_pubs                               2.0099e-02  3.2852e-03   6.1180 9.476e-10 ***
## cited_by                                 4.9092e-04  8.5958e-05   5.7111 1.122e-08 ***
## inferred_genderw                         5.6718e-02  7.7684e-02   0.7301    0.4653    
## as.factor(general_field)Medicine         1.1226e+00  1.7487e-01   6.4195 1.367e-10 ***
## as.factor(general_field)Social sciences  1.0582e+00  1.5829e-01   6.6851 2.308e-11 ***
## as.factor(general_field)STEM             1.4134e+00  1.6258e-01   8.6932 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_twitter)</code></pre>
<pre><code>##   McFadden 
## 0.06837218</code></pre>
</div>
<div id="gender-prof-and-coauthor-controls" class="section level2"
number="5.2">
<h2><span class="header-section-number">5.2</span> Gender, prof, and
coauthor controls</h2>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- glm(any_news~count_pubs + cited_by + inferred_gender + 
                     coa_tot_count_pubs + coa_tot_cited_by_total + 
                     coa_online_news_total + coa_twitter_total +
                     as.factor(general_field), 
                   data = prof_panel_filter,
                   family = &quot;binomial&quot;)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -5.7073e-03  1.2523e-01 -0.0456  0.963649    
## count_pubs                               7.5213e-03  2.1796e-03  3.4508  0.000559 ***
## cited_by                                 2.1541e-04  5.4121e-05  3.9802 6.886e-05 ***
## inferred_genderw                        -1.7360e-01  6.0437e-02 -2.8723  0.004075 ** 
## coa_tot_count_pubs                       7.4049e-06  8.4715e-05  0.0874  0.930345    
## coa_tot_cited_by_total                  -5.7670e-08  4.5369e-07 -0.1271  0.898851    
## coa_online_news_total                    1.5823e-04  1.4481e-04  1.0927  0.274533    
## coa_twitter_total                       -1.2371e-05  1.3471e-05 -0.9183  0.358445    
## as.factor(general_field)Medicine        -7.1624e-01  1.3924e-01 -5.1438 2.692e-07 ***
## as.factor(general_field)Social sciences -7.5360e-02  1.3147e-01 -0.5732  0.566495    
## as.factor(general_field)STEM            -6.0317e-01  1.3441e-01 -4.4874 7.209e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_news)</code></pre>
<pre><code>##  McFadden 
## 0.0183344</code></pre>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- glm(any_online_news~count_pubs + cited_by + inferred_gender + 
                            coa_tot_count_pubs + coa_tot_cited_by_total + 
                            coa_online_news_total + coa_twitter_total +
                            as.factor(general_field), 
                          data = prof_panel_filter,
                          family = &quot;binomial&quot;)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -2.2332e+00  1.5357e-01 -14.5420 &lt; 2.2e-16 ***
## count_pubs                               7.0865e-03  2.9979e-03   2.3638   0.01809 *  
## cited_by                                 2.4550e-03  1.1642e-04  21.0885 &lt; 2.2e-16 ***
## inferred_genderw                         2.7889e-01  5.2003e-02   5.3630 8.185e-08 ***
## coa_tot_count_pubs                      -3.5988e-04  1.8996e-04  -1.8945   0.05815 .  
## coa_tot_cited_by_total                   5.9516e-06  1.4741e-06   4.0375 5.402e-05 ***
## coa_online_news_total                    2.6659e-03  1.3021e-03   2.0473   0.04063 *  
## coa_twitter_total                        2.6226e-04  1.8395e-04   1.4257   0.15395    
## as.factor(general_field)Medicine         1.1469e+00  1.6449e-01   6.9724 3.117e-12 ***
## as.factor(general_field)Social sciences  7.9400e-01  1.5668e-01   5.0676 4.028e-07 ***
## as.factor(general_field)STEM             6.3024e-01  1.6040e-01   3.9291 8.526e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_online_news)</code></pre>
<pre><code>##  McFadden 
## 0.2718287</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- glm(any_twitter~count_pubs + cited_by + inferred_gender + 
                        coa_tot_count_pubs + coa_tot_cited_by_total + 
                        coa_online_news_total + coa_twitter_total +
                        as.factor(general_field), 
                      data = prof_panel_filter,
                      family = &quot;binomial&quot;)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -1.7213e+00  1.6034e-01 -10.7350 &lt; 2.2e-16 ***
## count_pubs                               9.7578e-03  2.8762e-03   3.3926 0.0006924 ***
## cited_by                                 4.3024e-04  8.5622e-05   5.0249 5.036e-07 ***
## inferred_genderw                         4.1937e-02  7.9349e-02   0.5285 0.5971426    
## coa_tot_count_pubs                       2.0220e-04  9.8026e-05   2.0627 0.0391409 *  
## coa_tot_cited_by_total                  -7.3218e-07  6.5803e-07  -1.1127 0.2658391    
## coa_online_news_total                   -4.5010e-05  1.5498e-04  -0.2904 0.7714975    
## coa_twitter_total                        2.4680e-05  2.0944e-05   1.1784 0.2386315    
## as.factor(general_field)Medicine         9.5845e-01  1.8148e-01   5.2813 1.282e-07 ***
## as.factor(general_field)Social sciences  9.4461e-01  1.6704e-01   5.6551 1.558e-08 ***
## as.factor(general_field)STEM             1.2155e+00  1.7016e-01   7.1433 9.114e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_twitter)</code></pre>
<pre><code>##   McFadden 
## 0.04789786</code></pre>
</div>
</div>
<div id="models-c-top-5-of-attention" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Models C: Top 5% of
attention</h1>
<p>Get a binary variable denoting whether professor has been in the top
5% of the attention for this source this year in their field:</p>
<pre class="r"><code>panel_filter_long &lt;- prof_panel_filter %&gt;%
  pivot_longer(online_news:news, names_to = &quot;measure&quot;, values_to = &quot;value&quot;)

top_5_attn &lt;- panel_filter_long %&gt;%
  filter(!is.na(general_field) &amp; !is.na(year) &amp; year &gt; 2011)%&gt;%
  group_by(general_field, year, measure)%&gt;%
  filter(quantile(value, 0.95, na.rm = TRUE)&lt;value)%&gt;%
  select(profile_id, general_field, year, measure, value)

top_5_attn$measure &lt;- paste0(top_5_attn$measure, &quot;_top_5&quot;)
# top_5_attn$value &lt;- 1

top_5_attn &lt;- top_5_attn %&gt;%
  pivot_wider(names_from = &quot;measure&quot;)%&gt;%
  mutate(across(contains(&#39;top_5&#39;),  ~ifelse(is.na(.), 0, 1)))

prof_panel_filter_top &lt;- merge(prof_panel_filter,
                               top_5_attn[c(&quot;year&quot;, &quot;profile_id&quot;, &quot;general_field&quot;, &quot;news_top_5&quot;, &quot;online_news_top_5&quot;, &quot;twitter_top_5&quot;)],
                               by = c(&quot;profile_id&quot;, &quot;year&quot;, &quot;general_field&quot;),
                               all.x = TRUE,
                               all.y = FALSE)</code></pre>
<div id="gender-and-prof-controls-1" class="section level2"
number="6.1">
<h2><span class="header-section-number">6.1</span> Gender and prof
controls</h2>
<div id="this-time-period" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> This time
period</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- glm(news_top_5~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter_top,
                  family = &quot;binomial&quot;)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -1.8545e+00  2.7370e-01 -6.7756 1.239e-11 ***
## count_pubs                              -1.3042e-02  4.7816e-03 -2.7276   0.00638 ** 
## cited_by                                 8.4962e-05  4.2851e-05  1.9827   0.04740 *  
## inferred_genderw                        -4.6013e-01  1.4366e-01 -3.2030   0.00136 ** 
## as.factor(general_field)Medicine         7.7064e-02  3.0548e-01  0.2523   0.80083    
## as.factor(general_field)Social sciences  7.8579e-03  2.8639e-01  0.0274   0.97811    
## as.factor(general_field)STEM            -1.7250e-01  2.9053e-01 -0.5937   0.55269    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_news)</code></pre>
<pre><code>##    McFadden 
## 0.008192899</code></pre>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- glm(online_news_top_5~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter_top,
                  family = &quot;binomial&quot;)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -2.4012e+00  2.1758e-01 -11.0360 &lt; 2.2e-16 ***
## count_pubs                               1.7841e-02  3.2672e-03   5.4606 4.745e-08 ***
## cited_by                                 5.8395e-04  8.4958e-05   6.8734 6.270e-12 ***
## inferred_genderw                         1.9638e-01  1.1797e-01   1.6646  0.095985 .  
## as.factor(general_field)Medicine        -1.5881e+00  2.7580e-01  -5.7581 8.508e-09 ***
## as.factor(general_field)Social sciences -1.7033e-01  2.2923e-01  -0.7431  0.457440    
## as.factor(general_field)STEM            -7.4599e-01  2.4190e-01  -3.0839  0.002043 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_online_news)</code></pre>
<pre><code>## McFadden 
## 0.122321</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- glm(twitter_top_5~count_pubs + cited_by + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter_top,
                  family = &quot;binomial&quot;)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -2.1645e+00  1.9730e-01 -10.9705 &lt; 2.2e-16 ***
## count_pubs                               1.4080e-02  3.1437e-03   4.4786 7.512e-06 ***
## cited_by                                 3.0753e-04  7.1108e-05   4.3249 1.526e-05 ***
## inferred_genderw                        -4.9972e-02  1.4190e-01  -0.3522 0.7247104    
## as.factor(general_field)Medicine        -9.2600e-01  2.5537e-01  -3.6262 0.0002877 ***
## as.factor(general_field)Social sciences -8.1956e-02  2.1300e-01  -0.3848 0.7004009    
## as.factor(general_field)STEM            -4.9495e-01  2.2118e-01  -2.2378 0.0252360 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_twitter)</code></pre>
<pre><code>##   McFadden 
## 0.05268453</code></pre>
</div>
<div id="lag" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Lag</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- glm(news_top_5~count_pubs_l + cited_by_l + inferred_gender + 
                     coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                     coa_online_news_total_l + coa_twitter_total_l +
                     as.factor(general_field), 
                   data = prof_panel_filter_top,
                   family = &quot;binomial&quot;)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -2.2203e+00  3.1855e-01 -6.9699 3.171e-12 ***
## count_pubs_l                            -9.9867e-03  4.9518e-03 -2.0168  0.043718 *  
## cited_by_l                               1.1922e-04  5.7331e-05  2.0795  0.037567 *  
## inferred_genderw                        -4.7749e-01  1.5375e-01 -3.1056  0.001899 ** 
## coa_tot_count_pubs_l                    -2.0148e-04  1.2326e-04 -1.6346  0.102126    
## coa_tot_cited_by_total_l                 4.1405e-07  6.0072e-07  0.6893  0.490659    
## coa_online_news_total_l                  2.1414e-04  1.2275e-04  1.7445  0.081066 .  
## coa_twitter_total_l                     -7.1832e-06  1.2561e-05 -0.5719  0.567407    
## as.factor(general_field)Medicine         2.9622e-01  3.5218e-01  0.8411  0.400287    
## as.factor(general_field)Social sciences  2.1168e-01  3.3427e-01  0.6332  0.526575    
## as.factor(general_field)STEM             9.7609e-02  3.3816e-01  0.2886  0.772854    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_news)</code></pre>
<pre><code>##    McFadden 
## 0.009656335</code></pre>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- glm(online_news_top_5~count_pubs_l + cited_by_l + inferred_gender + 
                            coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                            coa_online_news_total_l + coa_twitter_total_l +
                            as.factor(general_field), 
                          data = prof_panel_filter_top,
                          family = &quot;binomial&quot;)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -2.3188e+00  2.2313e-01 -10.3920 &lt; 2.2e-16 ***
## count_pubs_l                             1.6819e-02  3.5889e-03   4.6865 2.779e-06 ***
## cited_by_l                               6.3025e-04  1.1298e-04   5.5787 2.424e-08 ***
## inferred_genderw                         1.9868e-01  1.1955e-01   1.6619  0.096523 .  
## coa_tot_count_pubs_l                    -3.0764e-04  1.0678e-04  -2.8811  0.003963 ** 
## coa_tot_cited_by_total_l                 2.5473e-07  6.6882e-07   0.3809  0.703299    
## coa_online_news_total_l                  1.2036e-03  1.2454e-04   9.6642 &lt; 2.2e-16 ***
## coa_twitter_total_l                     -8.9339e-05  1.2501e-05  -7.1465 8.902e-13 ***
## as.factor(general_field)Medicine        -1.5621e+00  2.7148e-01  -5.7540 8.713e-09 ***
## as.factor(general_field)Social sciences -1.7934e-01  2.3599e-01  -0.7599  0.447301    
## as.factor(general_field)STEM            -7.5978e-01  2.4690e-01  -3.0773  0.002089 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_online_news)</code></pre>
<pre><code>##  McFadden 
## 0.1320758</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- glm(twitter_top_5~count_pubs_l + cited_by_l + inferred_gender + 
                        coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                        coa_online_news_total_l + coa_twitter_total_l +
                        as.factor(general_field), 
                      data = prof_panel_filter_top,
                      family = &quot;binomial&quot;)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -2.0483e+00  2.1170e-01 -9.6755 &lt; 2.2e-16 ***
## count_pubs_l                             1.2249e-02  3.9356e-03  3.1123 0.0018566 ** 
## cited_by_l                               3.8360e-04  8.9180e-05  4.3014 1.697e-05 ***
## inferred_genderw                        -6.5646e-02  1.4359e-01 -0.4572 0.6475487    
## coa_tot_count_pubs_l                    -1.3977e-04  1.4680e-04 -0.9521 0.3410495    
## coa_tot_cited_by_total_l                -8.1806e-07  7.9020e-07 -1.0353 0.3005508    
## coa_online_news_total_l                  2.2699e-04  1.7081e-04  1.3289 0.1838713    
## coa_twitter_total_l                      7.5026e-06  1.4852e-05  0.5052 0.6134420    
## as.factor(general_field)Medicine        -9.3604e-01  2.6494e-01 -3.5330 0.0004108 ***
## as.factor(general_field)Social sciences -1.1943e-01  2.2623e-01 -0.5279 0.5975558    
## as.factor(general_field)STEM            -5.5446e-01  2.3495e-01 -2.3599 0.0182795 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_twitter)</code></pre>
<pre><code>##   McFadden 
## 0.05372691</code></pre>
</div>
<div id="totals" class="section level3" number="6.1.3">
<h3><span class="header-section-number">6.1.3</span> Totals</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- glm(news_top_5~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                     coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                     coa_online_news_total_l + coa_twitter_total_l +
                     as.factor(general_field), 
                   data = prof_panel_filter_top,
                   family = &quot;binomial&quot;)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -2.2963e+00  3.1448e-01 -7.3019 2.836e-13 ***
## count_pubs_total_l                       1.5455e-04  3.2807e-04  0.4711  0.637563    
## cited_by_total_all_l                     4.9310e-06  7.9026e-06  0.6240  0.532648    
## inferred_genderw                        -4.5567e-01  1.5590e-01 -2.9229  0.003468 ** 
## coa_tot_count_pubs_l                    -2.7048e-04  1.4389e-04 -1.8798  0.060132 .  
## coa_tot_cited_by_total_l                 6.3307e-07  6.7233e-07  0.9416  0.346397    
## coa_online_news_total_l                  1.6103e-04  1.1648e-04  1.3824  0.166851    
## coa_twitter_total_l                     -2.7912e-06  1.1881e-05 -0.2349  0.814255    
## as.factor(general_field)Medicine         2.0563e-01  3.4256e-01  0.6003  0.548328    
## as.factor(general_field)Social sciences  1.9672e-01  3.3009e-01  0.5960  0.551206    
## as.factor(general_field)STEM             7.6326e-02  3.3268e-01  0.2294  0.818539    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_news)</code></pre>
<pre><code>##    McFadden 
## 0.007893276</code></pre>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- glm(online_news_top_5~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                            coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                            coa_online_news_total_l + coa_twitter_total_l +
                            as.factor(general_field), 
                          data = prof_panel_filter_top,
                          family = &quot;binomial&quot;)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -2.2594e+00  2.2625e-01 -9.9862 &lt; 2.2e-16 ***
## count_pubs_total_l                       3.3363e-04  2.9611e-04  1.1267   0.25986    
## cited_by_total_all_l                     5.8041e-05  8.1717e-06  7.1026 1.224e-12 ***
## inferred_genderw                         1.8770e-01  1.2320e-01  1.5236   0.12762    
## coa_tot_count_pubs_l                    -1.2916e-04  9.0659e-05 -1.4246   0.15426    
## coa_tot_cited_by_total_l                 7.0417e-08  5.3109e-07  0.1326   0.89452    
## coa_online_news_total_l                  1.0690e-03  1.4264e-04  7.4946 6.651e-14 ***
## coa_twitter_total_l                     -5.8309e-05  1.4147e-05 -4.1217 3.761e-05 ***
## as.factor(general_field)Medicine        -1.1112e+00  2.4975e-01 -4.4491 8.622e-06 ***
## as.factor(general_field)Social sciences -5.0595e-02  2.3501e-01 -0.2153   0.82954    
## as.factor(general_field)STEM            -5.8340e-01  2.3674e-01 -2.4643   0.01373 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_online_news)</code></pre>
<pre><code>##   McFadden 
## 0.09940064</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- glm(twitter_top_5~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                        coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                        coa_online_news_total_l + coa_twitter_total_l +
                        as.factor(general_field), 
                      data = prof_panel_filter_top,
                      family = &quot;binomial&quot;)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -1.9089e+00  2.1510e-01 -8.8742 &lt; 2.2e-16 ***
## count_pubs_total_l                      -5.1348e-04  4.2124e-04 -1.2190   0.22285    
## cited_by_total_all_l                     4.5029e-05  1.0017e-05  4.4954 6.945e-06 ***
## inferred_genderw                        -1.1505e-01  1.4257e-01 -0.8069   0.41971    
## coa_tot_count_pubs_l                     8.0764e-06  9.8948e-05  0.0816   0.93495    
## coa_tot_cited_by_total_l                -7.6666e-07  6.3640e-07 -1.2047   0.22833    
## coa_online_news_total_l                  2.1996e-04  1.5806e-04  1.3916   0.16404    
## coa_twitter_total_l                      1.8392e-05  1.4931e-05  1.2318   0.21802    
## as.factor(general_field)Medicine        -6.1008e-01  2.4851e-01 -2.4550   0.01409 *  
## as.factor(general_field)Social sciences -3.2785e-02  2.2627e-01 -0.1449   0.88479    
## as.factor(general_field)STEM            -4.5090e-01  2.3116e-01 -1.9506   0.05111 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_twitter)</code></pre>
<pre><code>##   McFadden 
## 0.03682796</code></pre>
</div>
</div>
<div id="gender-prof-and-coauthor-controls-1" class="section level2"
number="6.2">
<h2><span class="header-section-number">6.2</span> Gender, prof, and
coauthor controls</h2>
<div id="this-time-period-1" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> This time
period:</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- glm(any_news~count_pubs + cited_by + inferred_gender + 
                     coa_tot_count_pubs + coa_tot_cited_by_total + 
                     coa_online_news_total + coa_twitter_total +
                     as.factor(general_field), 
                   data = prof_panel_filter,
                   family = &quot;binomial&quot;)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -5.7073e-03  1.2523e-01 -0.0456  0.963649    
## count_pubs                               7.5213e-03  2.1796e-03  3.4508  0.000559 ***
## cited_by                                 2.1541e-04  5.4121e-05  3.9802 6.886e-05 ***
## inferred_genderw                        -1.7360e-01  6.0437e-02 -2.8723  0.004075 ** 
## coa_tot_count_pubs                       7.4049e-06  8.4715e-05  0.0874  0.930345    
## coa_tot_cited_by_total                  -5.7670e-08  4.5369e-07 -0.1271  0.898851    
## coa_online_news_total                    1.5823e-04  1.4481e-04  1.0927  0.274533    
## coa_twitter_total                       -1.2371e-05  1.3471e-05 -0.9183  0.358445    
## as.factor(general_field)Medicine        -7.1624e-01  1.3924e-01 -5.1438 2.692e-07 ***
## as.factor(general_field)Social sciences -7.5360e-02  1.3147e-01 -0.5732  0.566495    
## as.factor(general_field)STEM            -6.0317e-01  1.3441e-01 -4.4874 7.209e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_news)</code></pre>
<pre><code>##  McFadden 
## 0.0183344</code></pre>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- glm(any_online_news~count_pubs + cited_by + inferred_gender + 
                            coa_tot_count_pubs + coa_tot_cited_by_total + 
                            coa_online_news_total + coa_twitter_total +
                            as.factor(general_field), 
                          data = prof_panel_filter,
                          family = &quot;binomial&quot;)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -2.2332e+00  1.5357e-01 -14.5420 &lt; 2.2e-16 ***
## count_pubs                               7.0865e-03  2.9979e-03   2.3638   0.01809 *  
## cited_by                                 2.4550e-03  1.1642e-04  21.0885 &lt; 2.2e-16 ***
## inferred_genderw                         2.7889e-01  5.2003e-02   5.3630 8.185e-08 ***
## coa_tot_count_pubs                      -3.5988e-04  1.8996e-04  -1.8945   0.05815 .  
## coa_tot_cited_by_total                   5.9516e-06  1.4741e-06   4.0375 5.402e-05 ***
## coa_online_news_total                    2.6659e-03  1.3021e-03   2.0473   0.04063 *  
## coa_twitter_total                        2.6226e-04  1.8395e-04   1.4257   0.15395    
## as.factor(general_field)Medicine         1.1469e+00  1.6449e-01   6.9724 3.117e-12 ***
## as.factor(general_field)Social sciences  7.9400e-01  1.5668e-01   5.0676 4.028e-07 ***
## as.factor(general_field)STEM             6.3024e-01  1.6040e-01   3.9291 8.526e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_online_news)</code></pre>
<pre><code>##  McFadden 
## 0.2718287</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- glm(any_twitter~count_pubs + cited_by + inferred_gender + 
                        coa_tot_count_pubs + coa_tot_cited_by_total + 
                        coa_online_news_total + coa_twitter_total +
                        as.factor(general_field), 
                      data = prof_panel_filter,
                      family = &quot;binomial&quot;)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -1.7213e+00  1.6034e-01 -10.7350 &lt; 2.2e-16 ***
## count_pubs                               9.7578e-03  2.8762e-03   3.3926 0.0006924 ***
## cited_by                                 4.3024e-04  8.5622e-05   5.0249 5.036e-07 ***
## inferred_genderw                         4.1937e-02  7.9349e-02   0.5285 0.5971426    
## coa_tot_count_pubs                       2.0220e-04  9.8026e-05   2.0627 0.0391409 *  
## coa_tot_cited_by_total                  -7.3218e-07  6.5803e-07  -1.1127 0.2658391    
## coa_online_news_total                   -4.5010e-05  1.5498e-04  -0.2904 0.7714975    
## coa_twitter_total                        2.4680e-05  2.0944e-05   1.1784 0.2386315    
## as.factor(general_field)Medicine         9.5845e-01  1.8148e-01   5.2813 1.282e-07 ***
## as.factor(general_field)Social sciences  9.4461e-01  1.6704e-01   5.6551 1.558e-08 ***
## as.factor(general_field)STEM             1.2155e+00  1.7016e-01   7.1433 9.114e-13 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_twitter)</code></pre>
<pre><code>##   McFadden 
## 0.04789786</code></pre>
</div>
<div id="lag-1" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Lag</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- glm(any_news~count_pubs_l + cited_by_l + inferred_gender + 
                     coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                     coa_online_news_total_l + coa_twitter_total_l +
                     as.factor(general_field), 
                   data = prof_panel_filter,
                   family = &quot;binomial&quot;)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -2.4454e-02  1.3126e-01 -0.1863 0.8522076    
## count_pubs_l                             9.0524e-03  2.4795e-03  3.6508 0.0002614 ***
## cited_by_l                               2.3116e-04  5.6663e-05  4.0795 4.513e-05 ***
## inferred_genderw                        -1.6113e-01  6.1628e-02 -2.6146 0.0089335 ** 
## coa_tot_count_pubs_l                    -2.0748e-05  9.2329e-05 -0.2247 0.8221943    
## coa_tot_cited_by_total_l                -2.7890e-08  5.2043e-07 -0.0536 0.9572624    
## coa_online_news_total_l                  5.3657e-05  1.5041e-04  0.3567 0.7212919    
## coa_twitter_total_l                     -4.6666e-06  1.4272e-05 -0.3270 0.7436828    
## as.factor(general_field)Medicine        -6.9961e-01  1.4546e-01 -4.8095 1.513e-06 ***
## as.factor(general_field)Social sciences -5.2739e-02  1.3753e-01 -0.3835 0.7013734    
## as.factor(general_field)STEM            -5.8858e-01  1.4041e-01 -4.1920 2.765e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_news)</code></pre>
<pre><code>##   McFadden 
## 0.01857066</code></pre>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- glm(any_online_news~count_pubs_l + cited_by_l + inferred_gender + 
                            coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                            coa_online_news_total_l + coa_twitter_total_l +
                            as.factor(general_field), 
                          data = prof_panel_filter,
                          family = &quot;binomial&quot;)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -2.1324e+00  1.5267e-01 -13.9673 &lt; 2.2e-16 ***
## count_pubs_l                             1.1144e-02  3.2771e-03   3.4006 0.0006724 ***
## cited_by_l                               2.5943e-03  1.2609e-04  20.5749 &lt; 2.2e-16 ***
## inferred_genderw                         2.9072e-01  5.4165e-02   5.3673 7.994e-08 ***
## coa_tot_count_pubs_l                    -3.7471e-04  2.2359e-04  -1.6759 0.0937625 .  
## coa_tot_cited_by_total_l                 5.2343e-06  1.7272e-06   3.0306 0.0024409 ** 
## coa_online_news_total_l                  1.5639e-03  8.3601e-04   1.8706 0.0613958 .  
## coa_twitter_total_l                      4.2707e-04  9.8409e-05   4.3397 1.427e-05 ***
## as.factor(general_field)Medicine         1.2436e+00  1.6426e-01   7.5711 3.701e-14 ***
## as.factor(general_field)Social sciences  8.0195e-01  1.5617e-01   5.1352 2.819e-07 ***
## as.factor(general_field)STEM             6.1034e-01  1.6001e-01   3.8144 0.0001365 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_online_news)</code></pre>
<pre><code>##  McFadden 
## 0.2661066</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- glm(any_twitter~count_pubs_l + cited_by_l + inferred_gender + 
                        coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                        coa_online_news_total_l + coa_twitter_total_l +
                        as.factor(general_field), 
                      data = prof_panel_filter,
                      family = &quot;binomial&quot;)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -1.6122e+00  1.6455e-01 -9.7981 &lt; 2.2e-16 ***
## count_pubs_l                             1.2697e-02  3.2202e-03  3.9428 8.053e-05 ***
## cited_by_l                               4.0107e-04  8.8500e-05  4.5319 5.846e-06 ***
## inferred_genderw                         5.3746e-02  8.0061e-02  0.6713   0.50202    
## coa_tot_count_pubs_l                     1.7641e-04  9.5427e-05  1.8487   0.06451 .  
## coa_tot_cited_by_total_l                -6.7743e-07  7.0506e-07 -0.9608   0.33665    
## coa_online_news_total_l                 -1.4681e-04  1.9214e-04 -0.7641   0.44482    
## coa_twitter_total_l                      3.9180e-05  2.7585e-05  1.4204   0.15550    
## as.factor(general_field)Medicine         8.8539e-01  1.8520e-01  4.7806 1.747e-06 ***
## as.factor(general_field)Social sciences  8.8935e-01  1.7127e-01  5.1927 2.073e-07 ***
## as.factor(general_field)STEM             1.1622e+00  1.7426e-01  6.6692 2.572e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_twitter)</code></pre>
<pre><code>##   McFadden 
## 0.04487318</code></pre>
</div>
<div id="totals-1" class="section level3" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Totals</h3>
<p>News attention and gender:</p>
<pre class="r"><code>gender_news &lt;- glm(any_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                     coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                     coa_online_news_total_l + coa_twitter_total_l +
                     as.factor(general_field), 
                   data = prof_panel_filter,
                   family = &quot;binomial&quot;)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -1.5275e-01  1.3494e-01 -1.1319    0.2577    
## count_pubs_total_l                       1.5408e-03  3.2991e-04  4.6703 3.008e-06 ***
## cited_by_total_all_l                     8.6539e-06  5.7272e-06  1.5110    0.1308    
## inferred_genderw                        -9.7876e-02  6.2257e-02 -1.5721    0.1159    
## coa_tot_count_pubs_l                    -7.0414e-05  9.4788e-05 -0.7429    0.4576    
## coa_tot_cited_by_total_l                 3.8196e-09  5.5390e-07  0.0069    0.9945    
## coa_online_news_total_l                  3.1301e-05  1.3735e-04  0.2279    0.8197    
## coa_twitter_total_l                      3.7311e-06  1.2731e-05  0.2931    0.7695    
## as.factor(general_field)Medicine        -6.8176e-01  1.4306e-01 -4.7655 1.884e-06 ***
## as.factor(general_field)Social sciences -4.1895e-02  1.3726e-01 -0.3052    0.7602    
## as.factor(general_field)STEM            -5.9046e-01  1.3966e-01 -4.2278 2.360e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_news)</code></pre>
<pre><code>##   McFadden 
## 0.02127149</code></pre>
<p>Online news attention and gender:</p>
<pre class="r"><code>gender_online_news &lt;- glm(any_online_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                            coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                            coa_online_news_total_l + coa_twitter_total_l +
                            as.factor(general_field), 
                          data = prof_panel_filter,
                          family = &quot;binomial&quot;)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error  z value  Pr(&gt;|z|)    
## (Intercept)                             -2.1192e+00  1.6106e-01 -13.1581 &lt; 2.2e-16 ***
## count_pubs_total_l                       5.9715e-04  4.0954e-04   1.4581   0.14482    
## cited_by_total_all_l                     1.8152e-04  1.7829e-05  10.1811 &lt; 2.2e-16 ***
## inferred_genderw                         3.1154e-01  5.7106e-02   5.4556 4.882e-08 ***
## coa_tot_count_pubs_l                    -2.0438e-04  1.3612e-04  -1.5015   0.13323    
## coa_tot_cited_by_total_l                 5.2414e-06  1.3425e-06   3.9042 9.454e-05 ***
## coa_online_news_total_l                  2.3557e-03  1.0475e-03   2.2488   0.02453 *  
## coa_twitter_total_l                      5.9416e-04  1.2294e-04   4.8329 1.345e-06 ***
## as.factor(general_field)Medicine         1.7009e+00  1.6631e-01  10.2274 &lt; 2.2e-16 ***
## as.factor(general_field)Social sciences  9.8024e-01  1.5923e-01   6.1560 7.459e-10 ***
## as.factor(general_field)STEM             8.8939e-01  1.6442e-01   5.4093 6.328e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_online_news)</code></pre>
<pre><code>##  McFadden 
## 0.2277168</code></pre>
<p>Twitter attention and gender:</p>
<pre class="r"><code>gender_twitter &lt;- glm(any_twitter~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                        coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                        coa_online_news_total_l + coa_twitter_total_l +
                        as.factor(general_field), 
                      data = prof_panel_filter,
                      family = &quot;binomial&quot;)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = &quot;HC0&quot;))</code></pre>
<pre><code>## 
## z test of coefficients:
## 
##                                            Estimate  Std. Error z value  Pr(&gt;|z|)    
## (Intercept)                             -1.6385e+00  1.6656e-01 -9.8370 &lt; 2.2e-16 ***
## count_pubs_total_l                       8.1026e-04  3.4625e-04  2.3401  0.019278 *  
## cited_by_total_all_l                     2.7228e-05  9.2378e-06  2.9474  0.003204 ** 
## inferred_genderw                         8.0752e-02  8.0604e-02  1.0018  0.316427    
## coa_tot_count_pubs_l                     2.1364e-04  1.0771e-04  1.9836  0.047304 *  
## coa_tot_cited_by_total_l                -4.9503e-07  7.4733e-07 -0.6624  0.507718    
## coa_online_news_total_l                 -1.5988e-04  1.9874e-04 -0.8045  0.421119    
## coa_twitter_total_l                      5.7862e-05  2.9647e-05  1.9517  0.050976 .  
## as.factor(general_field)Medicine         1.0180e+00  1.8119e-01  5.6183 1.928e-08 ***
## as.factor(general_field)Social sciences  9.2849e-01  1.7051e-01  5.4454 5.168e-08 ***
## as.factor(general_field)STEM             1.2171e+00  1.7316e-01  7.0289 2.082e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>PseudoR2(gender_twitter)</code></pre>
<pre><code>##   McFadden 
## 0.03892664</code></pre>
</div>
</div>
</div>

<div id="rmd-source-code">---
title: "Untitled"
author: "Ana Macanovic"
date: "2024-02-29"
---

```{r}
options(width = 120)
knitr::opts_chunk$set(cache = FALSE, cache.lazy = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```


Load the packages:
```{r message=  F, warning = F, eval = T}
library(groundhog)
packages_to_load <- c("readr", "dplyr", "tidyr", 
                      "tidyverse", "RPostgres", "lubridate", "psych",
                      "gridExtra", "DescTools",
                      "panelr", "skimr", "car","ggeffects",
                      "lmtest", "sandwich",
                      "stargazer","plm")
groundhog.library(packages_to_load, date = "2023-12-01")

```

# Data preparation

Load the panel:
```{r warning = F, message = F}
prof_panel <- read_csv("panel_datasets/prof_year_p_c_g_a_t_l_l_18_3.csv")
prof_panel_coa <- read_csv("panel_datasets/prof_panel_combined_no_lexis_19_3.csv")

# combine the two, since the latter mixes nexis data
lexis_data <- prof_panel %>%
  select(profile_id, year, contains("lexis"))

prof_panel_coa <- merge(prof_panel_coa,
                        lexis_data,
                        by= c("profile_id", "year"))

# recode the fields
prof_panel_coa <- prof_panel_coa %>% 
  mutate(general_field = case_match(
    overall_field,
    "Arts and Humanities"  ~ "Arts & Humanities",
    c("Biochemistry, Genetics and Molecular Biology","Agricultural and Biological Sciences",
      "Chemical Engineering", "Chemistry",  "Computer Science", "Decision Sciences",
      "Earth and Planetary Sciences", "Energy", "Engineering", "Environmental Science",
      "Immunology and Microbiology", "Materials Science", "Mathematics", "Neuroscience", 
      "Physics and Astronomy" ) ~ "STEM",
    c("Dentistry", "Health Professions", "Medicine") ~ "Medicine",
    c("Business, Management and Accounting", "Economics, Econometrics and Finance",
      "Psychology", "Social Sciences") ~ "Social sciences"))

prof_panel_coa <- prof_panel_coa %>% 
  mutate(general_field_yearly = case_match(
    yearly_field,
    "Arts and Humanities"  ~ "Arts & Humanities",
    c("Biochemistry, Genetics and Molecular Biology","Agricultural and Biological Sciences",
      "Chemical Engineering", "Chemistry",  "Computer Science", "Decision Sciences",
      "Earth and Planetary Sciences", "Energy", "Engineering", "Environmental Science",
      "Immunology and Microbiology", "Materials Science", "Mathematics", "Neuroscience", 
      "Physics and Astronomy" ) ~ "STEM",
    c("Dentistry", "Health Professions", "Medicine") ~ "Medicine",
    c("Business, Management and Accounting", "Economics, Econometrics and Finance",
      "Psychology", "Social Sciences") ~ "Social sciences"))
```
 
Rename the columns neatly:
```{r}
prof_panel_tidy <- prof_panel_coa %>%
  select(-c(cited_by_before_2012, cited_by_total_oa, cited_by_total_oa_l, dupl, dupl_l, 
           coa_cited_by_before_2012, coa_count_pubs_before_2012, coa_cited_by_before_2012_l,
           coa_count_pubs_before_2012, prof_tot_count_pubs_total_oa, prof_tot_cited_by_total_oa,
           prof_tot_cited_by_before_2012, prof_tot_count_pubs_before_2012  ))%>%
  rename(
    online_news = attn_news_by,
    online_news_total = attn_news_by_total,
    online_news_l = attn_news_by_l,
    online_news_total_l = attn_news_by_total_l,
    blogs = attn_blogs_by,
    blogs_total = attn_blogs_by_total,
    blogs_l = attn_blogs_by_l,
    blogs_total_l = attn_blogs_by_total_l,
    twitter = attn_twitter_by,
    twitter_total = attn_twitter_by_total,
    twitter_l = attn_twitter_by_l,
    twitter_total_l = attn_twitter_by_total_l,
    grant_veni = veni,
    grant_veni_l = veni_l,
    grant_vidi = vidi,
    grant_vidi_l = vidi_l,    
    grant_vici = vici,
    grant_vici_l = vici_l,
    grant_stevin = stevin,
    grant_stevin_l = stevin_l,
    grant_spinoza = spinoza,
    grant_spinoza_l = spinoza_l,
    grant_starting = starting,
    grant_starting_l = starting_l,
    grant_advanced = advanced,
    grant_advanced_l = advanced_l,
    grant_consolidator = consolidator,
    grant_consolidator_l = consolidator_l,
    grant_synergy = synergy,
    grant_synergy_l = synergy_l,
    coa_online_news = coa_attn_news_by,
    coa_blogs = coa_attn_blog_by,
    coa_twitter = coa_attn_twitter_by,
    coa_online_news_total = coa_attn_news_by_total,
    coa_blogs_total = coa_attn_blog_by_total,
    coa_twitter_total = coa_attn_twitter_by_total,
    coa_online_news_l = coa_attn_news_by_l,
    coa_blogs_l = coa_attn_blog_by_l,
    coa_twitter_l = coa_attn_twitter_by_l,
    coa_online_news_total_l = coa_attn_news_by_total_l,
    coa_blogs_total_l = coa_attn_blog_by_total_l,
    coa_twitter_total_l = coa_attn_twitter_by_total_l,
    coa_tot_count_pubs = prof_tot_count_pubs, 
    coa_tot_cited_by = prof_tot_cited_by,
    coa_tot_count_pubs_total = prof_tot_count_pubs_total_all,
    coa_tot_cited_by_total = prof_tot_cited_by_total_all,
    coa_tot_online_news = prof_tot_coa_attn_news_by,
    coa_tot_blogs = prof_tot_coa_attn_blog_by,
    coa_tot_twitter = prof_tot_coa_attn_twitter_by,
    coa_tot_online_news_total = prof_tot_coa_attn_news_by_total,
    coa_tot_blogs_total = prof_tot_coa_attn_blog_by_total,
    coa_tot_twitter_total = prof_tot_coa_attn_twitter_by_total,
    coa_tot_unique_m = prof_tot_unique_coa_m,
    coa_tot_unique_w = prof_tot_unique_coa_w,
    coa_tot_unique_u = prof_tot_unique_coa_u,
    coa_tot_count_pubs_l = prof_tot_count_pubs_l, 
    coa_tot_cited_by_l = prof_tot_cited_by_l,
    coa_tot_count_pubs_total_l = prof_tot_count_pubs_total_all_l,
    coa_tot_cited_by_total_l = prof_tot_cited_by_total_all_l,
    coa_tot_online_news_l = prof_tot_coa_attn_news_by_l,
    coa_tot_blogs_l = prof_tot_coa_attn_blog_by_l,
    coa_tot_twitter_l = prof_tot_coa_attn_twitter_by_l,
    coa_tot_online_news_total_l = prof_tot_coa_attn_news_by_total_l,
    coa_tot_blogs_total_l = prof_tot_coa_attn_blog_by_total_l,
    coa_tot_twitter_total_l = prof_tot_coa_attn_twitter_by_total_l,
    coa_tot_unique_m_l = prof_tot_unique_coa_m_l,
    coa_tot_unique_w_l = prof_tot_unique_coa_w_l,
    coa_tot_unique_u_l = prof_tot_unique_coa_u_l,
    news_national = lexis_national,
    news_regional = lexis_regional,
    news_intl = lexis_intl,
    news = lexis_all,
    news_national_total = lexis_national_total,
    news_regional_total = lexis_regional_total,
    news_intl_total = lexis_intl_total,
    news_total = lexis_all_total,
    news_national_l = lexis_national_l,
    news_regional_l = lexis_regional_l,
    news_intl_l = lexis_intl_l,
    news_l = lexis_all_l,
    news_national_total_l = lexis_national_total_l,
    news_regional_total_l = lexis_regional_total_l,
    news_intl_total_l = lexis_intl_total_l,
    news_total_l = lexis_all_total_l)
```
 
Select relevant columns and tidy everything up:
```{r}
prof_panel_tidy <- prof_panel_tidy %>%
  # but not 2024
  filter(year < 2024 & !is.na(year))

# tidy up mentions
prof_panel_tidy$online_news <- prof_panel_tidy$online_news + prof_panel_tidy$blogs
prof_panel_tidy$online_news_l <- prof_panel_tidy$online_news_l + prof_panel_tidy$blogs_l
prof_panel_tidy$online_news_total_l <- prof_panel_tidy$online_news_total_l + prof_panel_tidy$blogs_total_l

# coauthors this year
prof_panel_tidy$coa_online_news <- prof_panel_tidy$coa_online_news + prof_panel_tidy$coa_blogs
prof_panel_tidy$coa_online_news_l <- prof_panel_tidy$coa_online_news_l + prof_panel_tidy$coa_blogs_l
prof_panel_tidy$coa_online_news_total <- prof_panel_tidy$coa_online_news_total + prof_panel_tidy$coa_blogs_total
prof_panel_tidy$coa_online_news_total_l <- prof_panel_tidy$coa_online_news_total_l + prof_panel_tidy$coa_blogs_total_l

# all coauthors up until now
prof_panel_tidy$coa_tot_online_news <- prof_panel_tidy$coa_tot_online_news + prof_panel_tidy$coa_tot_blogs
prof_panel_tidy$coa_tot_online_news_l <- prof_panel_tidy$coa_tot_online_news_l + prof_panel_tidy$coa_tot_blogs_l
prof_panel_tidy$coa_tot_online_news_total <- prof_panel_tidy$coa_tot_online_news_total + prof_panel_tidy$coa_tot_blogs_total
prof_panel_tidy$coa_tot_online_news_total_l <- prof_panel_tidy$coa_tot_online_news_total_l + prof_panel_tidy$coa_tot_blogs_total_l

# get groups per years since entry
prof_panel_tidy$entry_batch <- cut(prof_panel_tidy$years_since_first_pub, breaks = seq(0, 50, by=10))
prof_panel_tidy$years_since_entry <- paste("up to", str_remove(str_split_i(as.character(prof_panel_tidy$entry_batch), ",", 2),"]"))
```

Alternatively, leave only those professors for whom we actually have lexis data:
```{r warning = F, message = F}
# ones we collected before 20.3. in the morning 
lexis_info <- file.info(list.files(path = "../lexis_crawl/downloads/zipfiles",
                                   pattern="*.zip",
                                   full.names = T))
lexis_rel_list <- filter(lexis_info,
                         mtime <= "2024-03-20 8:55:00")

lexis_rel_list$profile_id <- str_remove(str_remove(rownames(lexis_rel_list), "../lexis_crawl/downloads/zipfiles/"), ".zip")

# minus ones that are incomplete
missing_indices <- read_csv("../lexis_crawl/missing_indices.csv")

lexis_list <- filter(lexis_rel_list, ! profile_id %in% missing_indices$profile_id)

prof_panel_filter <- filter(prof_panel_tidy,
                            str_remove(profile_id, "https://www.narcis.nl/person/RecordID/") %in% lexis_list$profile_id)
```

# Simple descriptives

How many profs?
```{r}
length(unique(prof_panel_filter$profile_id))
```

Professors per field and subfield?
```{r}
print.data.frame(prof_panel_filter %>%
  distinct(profile_id, .keep_all = TRUE)%>%
  filter(!is.na(general_field))%>%
  group_by(general_field)%>%
  summarise(n = n())%>%
  arrange(-n))
```

## Correlations
A correlation matrix:
```{r}
round(cor(prof_panel_filter[c("count_pubs", "cited_by",
                              "online_news", "news", "twitter",
                              "coa_count_pubs", "coa_cited_by",
                              "coa_online_news", "coa_twitter")],
          use="complete.obs"), 2)
```

```{r}
round(cor(prof_panel_filter[c("count_pubs", "count_pubs_total_l",
                              "cited_by", "cited_by_total_all_l",
                              "online_news", "news", "twitter",
                              "coa_count_pubs", "coa_cited_by",
                              "coa_online_news", "coa_twitter")],
          use="complete.obs"), 2)
```
## VIFs

### News models
```{r}
test_vif <- plm(news~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model="pooling")
vif(test_vif)

test_vif <- plm(news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model="pooling")
vif(test_vif)
```
Online news
```{r}
test_vif <- plm(online_news~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model="pooling")
vif(test_vif)

test_vif <- plm(online_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model="pooling")
vif(test_vif)
```
Twitter
```{r}
test_vif <- plm(twitter~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model="pooling")
vif(test_vif)

test_vif <- plm(twitter~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs_l +
                  coa_tot_cited_by_total_l + coa_online_news_total_l + coa_twitter_total_l + as.factor(general_field), 
                data = prof_panel_filter,
                model="pooling")
vif(test_vif)
```
## Descriprives
And some descriptives:
```{r}
psych::describe(prof_panel_filter[c("count_pubs", "cited_by",
                              "online_news", "news", "twitter",
                              "coa_count_pubs", "coa_cited_by",
                              "coa_online_news", "coa_twitter")])
```

Get some panel statistics:
```{r}
xtsum::xtsum(
  prof_panel_filter,
  variables = c("count_pubs", "cited_by",
                "online_news", "news", "twitter",
                "coa_count_pubs", "coa_cited_by",
                "coa_online_news", "coa_twitter"),
  id = "profile_id",
  t = "year",
  na.rm = TRUE,
  return.data.frame = FALSE,
  dec = 2
)
```


# Big models

## Citations
```{r}
citations_full <- plm(cited_by ~ # professor publication variables
                  count_pubs_total_l + 
                  # gender
                  inferred_gender +
                  # attention variables
                  news_total_l + online_news_total_l + twitter_total_l +
                  # coauthor publication variables
                  coa_tot_count_pubs_l + coa_tot_cited_by_total_l +
                  # coauthor publication variables
                  coa_online_news_total_l + coa_twitter_total_l + 
                  # field and year controls
                  as.factor(general_field),
                 data = prof_panel_filter, model="pooling", index=c("profile_id", "year")) 

# clustered SE
coeftest(citations_full, vcov=vcovHC(citations_full,type="HC0",cluster="group"))


round(summary(citations_full)$r.squared,3)
```


## News

This time period's news given one's total citations/publications, past total 
attention, controlling for the field and year (Lexis sample only). Pooled model
with clustered SEs:
```{r}
news_full <- plm(news ~ # professor publication variables
                  count_pubs_total_l + cited_by_total_all_l + 
                  # gender
                  inferred_gender +
                  # attention variables
                  online_news_total_l + twitter_total_l +
                  # coauthor publication variables
                  coa_tot_count_pubs_l + coa_tot_cited_by_total_l +
                  # coauthor publication variables
                  coa_online_news_total_l + coa_twitter_total_l + 
                  # field and year controls
                  as.factor(general_field),
                 data = prof_panel_filter, model="pooling", index=c("profile_id", "year")) 

# clustered SE
coeftest(news_full, vcov=vcovHC(news_full,type="HC0",cluster="group"))


round(summary(news_full)$r.squared,3)
```
## Online news

This time period's online news given one's total citations/publications, past total 
attention, controlling for the field and year (Lexis sample only). Pooled model
with clustered SEs:
```{r}
online_news_full <- plm(online_news~ # professor publication variables
                  count_pubs_total_l + cited_by_total_all_l + 
                  # gender
                  inferred_gender +
                  # attention variables
                  news_total_l + twitter_total_l +
                  # coauthor publication variables
                  coa_tot_count_pubs_l + coa_tot_cited_by_total_l +
                  # coauthor publication variables
                  coa_online_news_total_l + coa_twitter_total_l + 
                  # field and year controls
                  as.factor(general_field),
                 data = prof_panel_filter, model="pooling", index=c("profile_id", "year")) 

# clustered SE
coeftest(online_news_full, vcov=vcovHC(online_news_full,type="HC0",cluster="group"))


round(summary(online_news_full)$r.squared,3)
```
## Twitter

This time period's twitter attention given one's total citations/publications, past total 
attention, controlling for the field and year (Lexis sample only). Pooled model
with clustered SEs:
```{r}
twitter_full <- plm(twitter~ # professor publication variables
                  count_pubs_total_l + cited_by_total_all_l + 
                  # gender
                  inferred_gender +
                  # attention variables
                  news_total_l + online_news_total_l +
                  # coauthor publication variables
                  coa_tot_count_pubs_l + coa_tot_cited_by_total_l +
                  # coauthor publication variables
                  coa_online_news_total_l + coa_twitter_total_l + 
                  # field and year controls
                  as.factor(general_field),
                 data = prof_panel_filter, model="pooling", index=c("profile_id", "year")) 

# clustered SE
coeftest(twitter_full, vcov=vcovHC(twitter_full,type="HC0",cluster="group"))


round(summary(twitter_full)$r.squared,3)
```

# Models A: Counts
## Only gender

Publications and gender:
```{r}
gender_pubs <- lm(count_pubs~inferred_gender, 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_pubs, vcov = vcovCL(gender_pubs, cluster = ~profile_id))
```
Citations and gender:
```{r}
gender_cits <- lm(cited_by~inferred_gender, 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_cits, vcov = vcovCL(gender_cits, cluster = ~profile_id))
```

Conventional news attention and gender:
```{r}
gender_online_news <- lm(news~inferred_gender, 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))
```

Online News attention and gender:
```{r}
gender_news <- lm(online_news~inferred_gender, 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))
```

Twitter attention and gender:
```{r}
gender_twitter <- lm(twitter~inferred_gender, 
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))
```

## Gender and fields

Reference:  "Arts & Humanities" 

Publications and gender:
```{r}
gender_pubs <- lm(count_pubs~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_pubs, vcov = vcovCL(gender_pubs, cluster = ~profile_id))
```
Citations and gender:
```{r}
gender_cits <- lm(cited_by~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_cits, vcov = vcovCL(gender_cits, cluster = ~profile_id))
```

Conventional news attention and gender:
```{r}
gender_online_news <- lm(news~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))
```
Online News attention and gender:
```{r}
gender_news <- lm(online_news~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))
```

Twitter attention and gender:
```{r}
gender_twitter <- lm(twitter~inferred_gender+as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))
```

## Gender and prof controls (not lagged)

News attention and gender:
```{r}
gender_news <- lm(news~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))

summary(gender_news)$adj.r.squared
```
Online news attention and gender:
```{r}
gender_online_news <- lm(online_news~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))

summary(gender_online_news)$adj.r.squared
```
Twitter attention and gender:
```{r}
gender_twitter <- lm(twitter~count_pubs + cited_by + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))

summary(gender_twitter)$adj.r.squared
```


## Gender and prof controls (lagged)

### News 
News attention and gender:
```{r}
gender_news <- lm(news~count_pubs_l + cited_by_l + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))

summary(gender_news)$adj.r.squared
```

Cumulative:

```{r}
gender_news <- lm(news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))

summary(gender_news)$adj.r.squared
```
### Online news
Online news attention and gender:
```{r}
gender_online_news <- lm(online_news~count_pubs_l + cited_by_l + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))

summary(gender_online_news)$adj.r.squared
```

Cumulative:
```{r}
gender_online_news <- lm(online_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))

summary(gender_news)$adj.r.squared
```

### Twitter
Twitter attention and gender:
```{r}
gender_twitter <- lm(twitter~count_pubs_l + cited_by_l + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))

summary(gender_twitter)$adj.r.squared
```

Cumulative:
```{r}
gender_twitter <- lm(twitter~count_pubs_total_l + cited_by_total_all_l + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))

summary(gender_twitter)$adj.r.squared
```

## Prof and coauathor controls

### Conventional news
News attention and gender:
```{r}
gender_news1 <- lm(news~count_pubs + cited_by + inferred_gender + coa_count_pubs +
                    coa_cited_by + coa_online_news + coa_twitter + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news1, vcov = vcovCL(gender_news1, cluster = ~profile_id))

summary(gender_news1)$adj.r.squared
```
Lagged controls:
```{r}
gender_news2 <- lm(news~count_pubs_l + cited_by_l + inferred_gender +
                    coa_count_pubs_l +
                    coa_cited_by_l + coa_online_news_l + coa_twitter_l + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news2, vcov = vcovCL(gender_news2, cluster = ~profile_id))

summary(gender_news2)$adj.r.squared
```
Coauthor totals:
```{r}
gender_news3 <- lm(news~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news3, vcov = vcovCL(gender_news3, cluster = ~profile_id))

summary(gender_news3)$adj.r.squared
```

All totals:
```{r}
gender_news4 <- lm(news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news4, vcov = vcovCL(gender_news4, cluster = ~profile_id))

summary(gender_news4)$adj.r.squared
```


### Online news
News attention and gender:
```{r}
gender_online_news1 <- lm(online_news~count_pubs + cited_by + inferred_gender + coa_count_pubs +
                    coa_cited_by + coa_online_news + coa_twitter + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_online_news1, vcov = vcovCL(gender_online_news1, cluster = ~profile_id))

summary(gender_online_news1)$adj.r.squared
```
Lagged controls:
```{r}
gender_online_news2 <- lm(online_news~count_pubs_l + cited_by_l + inferred_gender +
                    coa_count_pubs_l +
                    coa_cited_by_l + coa_online_news_l + coa_twitter_l + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_online_news2, vcov = vcovCL(gender_online_news2, cluster = ~profile_id))

summary(gender_online_news2)$adj.r.squared
```
Coauthor totals:
```{r}
gender_online_news3 <- lm(online_news~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_online_news3, vcov = vcovCL(gender_online_news3, cluster = ~profile_id))

summary(gender_online_news3)$adj.r.squared
```

All totals:
```{r}
gender_online_news4 <- lm(online_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_online_news4, vcov = vcovCL(gender_online_news4, cluster = ~profile_id))

summary(gender_online_news4)$adj.r.squared
```

### Twitter
News attention and gender:
```{r}
gender_twitter1 <- lm(twitter~count_pubs + cited_by + inferred_gender + coa_count_pubs +
                    coa_cited_by + coa_online_news + coa_twitter + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_twitter1, vcov = vcovCL(gender_twitter1, cluster = ~profile_id))

summary(gender_twitter1)$adj.r.squared
```
Lagged controls:
```{r}
gender_twitter2 <- lm(twitter~count_pubs_l + cited_by_l + inferred_gender +
                    coa_count_pubs_l +
                    coa_cited_by_l + coa_online_news_l + coa_twitter_l + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_twitter2, vcov = vcovCL(gender_twitter2, cluster = ~profile_id))

summary(gender_twitter2)$adj.r.squared
```
Coauthor totals:
```{r}
gender_twitter3 <- lm(twitter~count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_twitter3, vcov = vcovCL(gender_twitter3, cluster = ~profile_id))

summary(gender_twitter3)$adj.r.squared
```

All totals:
```{r}
gender_twitter4 <- lm(twitter~count_pubs_total_l + cited_by_total_all_l + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_twitter4, vcov = vcovCL(gender_twitter4, cluster = ~profile_id))

summary(gender_twitter4)$adj.r.squared
```


## Cumulative media attention?

News attention and gender:
```{r}
gender_news <- lm(news~news_l + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))

summary(gender_news)$adj.r.squared
```
Blog attention and gender:
```{r}
gender_online_news <- lm(blogs~blogs_l + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))

summary(gender_online_news)$adj.r.squared
```
Twitter attention and gender:
```{r}
gender_twitter <- lm(twitter~twitter_l + as.factor(general_field),
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))

summary(gender_twitter)$adj.r.squared
```

## Cumulative media attention, prof and coauthor controls
News attention and gender:
```{r}
gender_news <- lm(news~news_l + count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field) + as.factor(year), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))

summary(gender_news)$adj.r.squared
```
Online news and gender:
```{r}
gender_online_news <- lm(online_news~online_news_l + count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field) + as.factor(year), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))

summary(gender_online_news)$adj.r.squared
```
Twitter attention and gender:
```{r}
gender_twitter <- lm(twitter~twitter_l + count_pubs + cited_by + inferred_gender + coa_tot_count_pubs +
                    coa_tot_cited_by_total + coa_online_news_total + coa_twitter_total + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))

summary(gender_twitter)$adj.r.squared
```




## Cumulative media attention per gender?


News attention and gender:
```{r}
gender_news <- lm(news~news_l*inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id))

summary(gender_news)$adj.r.squared
```
Blog attention and gender:
```{r}
gender_online_news <- lm(online_news~online_news_l*inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter)

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id))

summary(gender_online_news)$adj.r.squared
```
Twitter attention and gender:
```{r}
gender_twitter <- lm(twitter~twitter_l*inferred_gender + as.factor(general_field) +years_since_first_pub*inferred_gender,
                  data = prof_panel_filter)

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id))

summary(gender_twitter)$adj.r.squared
```



the model above, watching out for totals etc. 
+ 
 
Network
- coauthors 
- coauthors cites
- coauthors attention
- are these for t or t-1

Share of coauthors in the high end of attention distribution.


- any attention (are you in the attention elite)
- amount of attention
- top 10%

PUB TYPE
- articles, books + book chapters
- preprints? conf. proceedings?



# Models B: Any attention

Get a binary variable denoting whether professor has gotten any attention this year:

```{r}
prof_panel_filter$any_news <- as.factor(ifelse(prof_panel_filter$news > 0, 1, 0))
prof_panel_filter$any_news_l <- as.factor(ifelse(prof_panel_filter$news_l > 0, 1, 0))

prof_panel_filter$any_online_news <- as.factor(ifelse(prof_panel_filter$online_news > 0, 1, 0))
prof_panel_filter$any_online_news_l <- as.factor(ifelse(prof_panel_filter$online_news_l > 0, 1, 0))

prof_panel_filter$any_twitter <- as.factor(ifelse(prof_panel_filter$twitter > 0, 1, 0))
prof_panel_filter$any_twitter_l <- as.factor(ifelse(prof_panel_filter$twitter_l > 0, 1, 0))
```

## Gender and prof controls
News attention and gender:
```{r}
gender_news <- glm(any_news~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter,
                  family = "binomial")

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_news)
```
Online news attention and gender:
```{r}
gender_online_news <- glm(any_online_news~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter,
                  family = "binomial")

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_online_news)
```
Twitter attention and gender:
```{r}
gender_twitter <- glm(any_twitter~count_pubs + cited_by + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter,
                  family = "binomial")

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_twitter)
```



## Gender, prof, and coauthor controls
News attention and gender:
```{r}
gender_news <- glm(any_news~count_pubs + cited_by + inferred_gender + 
                     coa_tot_count_pubs + coa_tot_cited_by_total + 
                     coa_online_news_total + coa_twitter_total +
                     as.factor(general_field), 
                   data = prof_panel_filter,
                   family = "binomial")

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_news)
```
Online news attention and gender:
```{r}
gender_online_news <- glm(any_online_news~count_pubs + cited_by + inferred_gender + 
                            coa_tot_count_pubs + coa_tot_cited_by_total + 
                            coa_online_news_total + coa_twitter_total +
                            as.factor(general_field), 
                          data = prof_panel_filter,
                          family = "binomial")

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_online_news)
```
Twitter attention and gender:
```{r}
gender_twitter <- glm(any_twitter~count_pubs + cited_by + inferred_gender + 
                        coa_tot_count_pubs + coa_tot_cited_by_total + 
                        coa_online_news_total + coa_twitter_total +
                        as.factor(general_field), 
                      data = prof_panel_filter,
                      family = "binomial")

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_twitter)
```




# Models C: Top 5% of attention

Get a binary variable denoting whether professor has been in the top 5% of the attention
for this source this year in their field:
```{r}
panel_filter_long <- prof_panel_filter %>%
  pivot_longer(online_news:news, names_to = "measure", values_to = "value")

top_5_attn <- panel_filter_long %>%
  filter(!is.na(general_field) & !is.na(year) & year > 2011)%>%
  group_by(general_field, year, measure)%>%
  filter(quantile(value, 0.95, na.rm = TRUE)<value)%>%
  select(profile_id, general_field, year, measure, value)

top_5_attn$measure <- paste0(top_5_attn$measure, "_top_5")
# top_5_attn$value <- 1

top_5_attn <- top_5_attn %>%
  pivot_wider(names_from = "measure")%>%
  mutate(across(contains('top_5'),  ~ifelse(is.na(.), 0, 1)))

prof_panel_filter_top <- merge(prof_panel_filter,
                               top_5_attn[c("year", "profile_id", "general_field", "news_top_5", "online_news_top_5", "twitter_top_5")],
                               by = c("profile_id", "year", "general_field"),
                               all.x = TRUE,
                               all.y = FALSE)
```

## Gender and prof controls

### This time period
News attention and gender:
```{r}
gender_news <- glm(news_top_5~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter_top,
                  family = "binomial")

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_news)
```
Online news attention and gender:
```{r}
gender_online_news <- glm(online_news_top_5~count_pubs + cited_by + inferred_gender + as.factor(general_field), 
                  data = prof_panel_filter_top,
                  family = "binomial")

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_online_news)
```
Twitter attention and gender:
```{r}
gender_twitter <- glm(twitter_top_5~count_pubs + cited_by + inferred_gender + as.factor(general_field),
                  data = prof_panel_filter_top,
                  family = "binomial")

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_twitter)
```

### Lag

News attention and gender:
```{r}
gender_news <- glm(news_top_5~count_pubs_l + cited_by_l + inferred_gender + 
                     coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                     coa_online_news_total_l + coa_twitter_total_l +
                     as.factor(general_field), 
                   data = prof_panel_filter_top,
                   family = "binomial")

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_news)
```
Online news attention and gender:
```{r}
gender_online_news <- glm(online_news_top_5~count_pubs_l + cited_by_l + inferred_gender + 
                            coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                            coa_online_news_total_l + coa_twitter_total_l +
                            as.factor(general_field), 
                          data = prof_panel_filter_top,
                          family = "binomial")

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_online_news)
```
Twitter attention and gender:
```{r}
gender_twitter <- glm(twitter_top_5~count_pubs_l + cited_by_l + inferred_gender + 
                        coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                        coa_online_news_total_l + coa_twitter_total_l +
                        as.factor(general_field), 
                      data = prof_panel_filter_top,
                      family = "binomial")

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_twitter)
```

### Totals
News attention and gender:
```{r}
gender_news <- glm(news_top_5~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                     coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                     coa_online_news_total_l + coa_twitter_total_l +
                     as.factor(general_field), 
                   data = prof_panel_filter_top,
                   family = "binomial")

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_news)
```
Online news attention and gender:
```{r}
gender_online_news <- glm(online_news_top_5~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                            coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                            coa_online_news_total_l + coa_twitter_total_l +
                            as.factor(general_field), 
                          data = prof_panel_filter_top,
                          family = "binomial")

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_online_news)
```
Twitter attention and gender:
```{r}
gender_twitter <- glm(twitter_top_5~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                        coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                        coa_online_news_total_l + coa_twitter_total_l +
                        as.factor(general_field), 
                      data = prof_panel_filter_top,
                      family = "binomial")

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_twitter)
```



## Gender, prof, and coauthor controls

### This time period:

News attention and gender:
```{r}
gender_news <- glm(any_news~count_pubs + cited_by + inferred_gender + 
                     coa_tot_count_pubs + coa_tot_cited_by_total + 
                     coa_online_news_total + coa_twitter_total +
                     as.factor(general_field), 
                   data = prof_panel_filter,
                   family = "binomial")

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_news)
```
Online news attention and gender:
```{r}
gender_online_news <- glm(any_online_news~count_pubs + cited_by + inferred_gender + 
                            coa_tot_count_pubs + coa_tot_cited_by_total + 
                            coa_online_news_total + coa_twitter_total +
                            as.factor(general_field), 
                          data = prof_panel_filter,
                          family = "binomial")

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_online_news)
```
Twitter attention and gender:
```{r}
gender_twitter <- glm(any_twitter~count_pubs + cited_by + inferred_gender + 
                        coa_tot_count_pubs + coa_tot_cited_by_total + 
                        coa_online_news_total + coa_twitter_total +
                        as.factor(general_field), 
                      data = prof_panel_filter,
                      family = "binomial")

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_twitter)
```

### Lag

News attention and gender:
```{r}
gender_news <- glm(any_news~count_pubs_l + cited_by_l + inferred_gender + 
                     coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                     coa_online_news_total_l + coa_twitter_total_l +
                     as.factor(general_field), 
                   data = prof_panel_filter,
                   family = "binomial")

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_news)
```
Online news attention and gender:
```{r}
gender_online_news <- glm(any_online_news~count_pubs_l + cited_by_l + inferred_gender + 
                            coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                            coa_online_news_total_l + coa_twitter_total_l +
                            as.factor(general_field), 
                          data = prof_panel_filter,
                          family = "binomial")

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_online_news)
```
Twitter attention and gender:
```{r}
gender_twitter <- glm(any_twitter~count_pubs_l + cited_by_l + inferred_gender + 
                        coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                        coa_online_news_total_l + coa_twitter_total_l +
                        as.factor(general_field), 
                      data = prof_panel_filter,
                      family = "binomial")

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_twitter)
```

### Totals
News attention and gender:
```{r}
gender_news <- glm(any_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                     coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                     coa_online_news_total_l + coa_twitter_total_l +
                     as.factor(general_field), 
                   data = prof_panel_filter,
                   family = "binomial")

# clustered SE
coeftest(gender_news, vcov = vcovCL(gender_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_news)
```
Online news attention and gender:
```{r}
gender_online_news <- glm(any_online_news~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                            coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                            coa_online_news_total_l + coa_twitter_total_l +
                            as.factor(general_field), 
                          data = prof_panel_filter,
                          family = "binomial")

coeftest(gender_online_news, vcov = vcovCL(gender_online_news, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_online_news)
```
Twitter attention and gender:
```{r}
gender_twitter <- glm(any_twitter~count_pubs_total_l + cited_by_total_all_l + inferred_gender + 
                        coa_tot_count_pubs_l + coa_tot_cited_by_total_l + 
                        coa_online_news_total_l + coa_twitter_total_l +
                        as.factor(general_field), 
                      data = prof_panel_filter,
                      family = "binomial")

coeftest(gender_twitter, vcov = vcovCL(gender_twitter, cluster = ~profile_id, type = "HC0"))

PseudoR2(gender_twitter)
```



</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("Various_regressions.Rmd");
  window.initializeCodeFolding("show" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
